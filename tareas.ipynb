{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64dbf540",
   "metadata": {},
   "source": [
    "Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc881425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import Video, display\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728c5aa",
   "metadata": {},
   "source": [
    "Extraemos las clases del modelo YOLO 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23885f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "vid = cv2.VideoCapture(\"C0142.MP4\")\n",
    "\n",
    "names = None\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if ret:\n",
    "        results = model(frame, show=False)\n",
    "        if names is None:\n",
    "            names = results[0].names\n",
    "        annotated_frame = results[0].plot()\n",
    "        cv2.imshow(\"Deteccion de YOLO\", annotated_frame)\n",
    "\n",
    "        # Salir del vídeo cuando presionamos ESC\n",
    "        if cv2.waitKey(1) & 0xFF == 27 or cv2.getWindowProperty(\"Deteccion de YOLO\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "    else:\n",
    "        # El vídeo ya se terminó\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Leemos las posibles clases\n",
    "with open(\"classes.txt\", \"w\") as f:\n",
    "    f.write(str(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d49077",
   "metadata": {},
   "source": [
    "### Mostramos el funcionamiento de nuestro modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('best.pt')\n",
    "\n",
    "vid = cv2.VideoCapture(\"C0142.MP4\")\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if ret:\n",
    "        results = model(frame, show=False)\n",
    "        annotated_frame = results[0].plot()\n",
    "        cv2.imshow(\"Deteccion de YOLO\", annotated_frame)\n",
    "\n",
    "        # Salir del vídeo cuando presionamos ESC\n",
    "        if cv2.waitKey(1) & 0xFF == 27 or cv2.getWindowProperty(\"Deteccion de YOLO\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "    else:\n",
    "        # El vídeo ya se terminó\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b0a81a",
   "metadata": {},
   "source": [
    "### Usamos el modelo pre-entrenado de YOLO y el nuestro en conjunto \n",
    "Utilizamos el modelo pre-entrenado para detectar personas y vehículos, posteriormente, cuando hayamos detectado un vehículo, se lo pasamos a nuestro modelo entrenado en matrículas para que le detecte la matrícula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d241ad",
   "metadata": {},
   "source": [
    "Código para las detecciones de OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1298f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código necesario para el VLM\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "import torch\n",
    "device = \"cpu\"  # or \"cpu\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-Instruct\")\n",
    "model = AutoModelForImageTextToText.from_pretrained(\"HuggingFaceTB/SmolVLM-Instruct\",\n",
    "                                                dtype=torch.bfloat16,\n",
    "                                                _attn_implementation=\"flash_attention_2\" if device == \"cuda\" else \"eager\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a69c034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Solo se está usando en el Tesseract (Se elimina?)\n",
    "def preprocess_for_ocr(img_crop, escala=4):\n",
    "\n",
    "    img = cv2.resize(img_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray_blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray_blur,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        13,\n",
    "        2\n",
    "    )\n",
    "\n",
    "    return thresh\n",
    "\n",
    "reader = easyocr.Reader(['es'], gpu=False) \n",
    "\n",
    "def ocr_easy(placa_crop, frame, x1, y1, last_plate=None):\n",
    "    escala = 3\n",
    "    placa_crop = cv2.resize(placa_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    gray = cv2.cvtColor(placa_crop, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    gray = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)\n",
    "\n",
    "    ocr_result = reader.readtext(\n",
    "        gray,\n",
    "        allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
    "        detail=1\n",
    "    )\n",
    "\n",
    "    text = \"\"\n",
    "\n",
    "    if len(ocr_result) > 0:\n",
    "        text = ocr_result[0][1].strip()\n",
    "        prob = ocr_result[0][2]\n",
    "\n",
    "        if len(text) >= 4 and prob > 0.5 and text != last_plate:\n",
    "            last_plate = text\n",
    "            timestamp = vid.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "            plate_pattern = re.compile(\"^[0-9]{4}[BCDFGHJKLMNPRSTVWXYZ]{3}$\")\n",
    "            if plate_pattern.match(text.strip()):\n",
    "                print(f\"[{timestamp:.2f}s] Matrícula: {text} (Conf: {prob:.2f})\")\n",
    "                cv2.putText(frame, f'{text}', (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                return\n",
    "   \n",
    "        return text\n",
    "    \n",
    "\n",
    "plate_img = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Read the text on this license plate.\"}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "def ocr_vlm(crop, frame, x1, y1, x2, y2):\n",
    "    \n",
    "    inputs = processor(text=prompt, images=[plate_img], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=10)\n",
    "        generated_texts = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        plate_text = generated_texts[0]\n",
    "        if \"Assistant: \" in plate_text:\n",
    "            index = plate_text.index(\"Assistant: \")+11\n",
    "            raw_text = plate_text[index:]\n",
    "\n",
    "    plate_pattern = re.compile(\"^[0-9]{4}[BCDFGHJKLMNPRSTVWXYZ]{3}$\")\n",
    "    if plate_pattern.match(raw_text.strip()):\n",
    "        cv2.putText(frame, raw_text, (x1, max(30, y1 - 10)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    return raw_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e835c4b",
   "metadata": {},
   "source": [
    "Código principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_MODEL_PATH = 'yolo11n.pt'\n",
    "OUR_MODEL_PATH = 'best.pt'\n",
    "\n",
    "VIDEO_PATH = \"Copy of C0142_1.mp4\"\n",
    "base_model = YOLO(BASE_MODEL_PATH)\n",
    "our_model = YOLO(OUR_MODEL_PATH)\n",
    "vid = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "frame_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "output_path = 'resultados.mp4'\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "def data_to_csv(registros):\n",
    "    columnas = [\n",
    "        \"fotograma\", \"tipo_objeto\", \"confianza\", \"id_tracking\",\n",
    "        \"x1\", \"y1\", \"x2\", \"y2\",\n",
    "        \"matricula_detectada\", \"conf_ocr\",\n",
    "        \"mx1\", \"my1\", \"mx2\", \"my2\",\n",
    "        \"texto_matricula\"\n",
    "    ]\n",
    "\n",
    "    with open(\"resultados.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter=';')\n",
    "        writer.writerow(columnas)    \n",
    "        writer.writerows(registros)  \n",
    "\n",
    "    print(\"Archivo 'resultados.csv' creado correctamente.\")\n",
    "\n",
    "\n",
    "classes = [0, 2, 3, 5, 7]    # Person, car, motorcycle, bus, truck\n",
    "\n",
    "car_boxes = []\n",
    "car_boxes_left_coords = []\n",
    "\n",
    "track_ids = set()\n",
    "count_classes = {\"person\": 0, \"car\": 0, \"motorcycle\": 0, \"bus\": 0, \"truck\": 0}\n",
    "\n",
    "save_csv = []\n",
    "frame_count = 0\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    frame_count += 1\n",
    "\n",
    "    if ret:\n",
    "        base_results = base_model.track(frame, persist=True, show=False, classes=classes)\n",
    "        plates_result = None\n",
    "        annotated_frame = base_results[0].plot()\n",
    "        boxes = list()\n",
    "\n",
    "        # Mostramos un recuadro arriba a la izquierda que muestre las matrículas que se vayan detectando\n",
    "        text_box_w = int(frame.shape[1]*0.25)\n",
    "        text_box_h = int(frame.shape[0]*0.09)\n",
    "        \n",
    "        cv2.rectangle(annotated_frame, (0, 0), (text_box_w, text_box_h), (0, 0, 0), -1)\n",
    "\n",
    "        last_plate = \"\"\n",
    "        show_plate_text = \"\"\n",
    "        \n",
    "        for result in base_results:\n",
    "            boxes += result.boxes\n",
    "        for box in boxes:\n",
    "            bounding_box = box.xyxy.tolist()\n",
    "            name = result[0].names[box.cls.int().item()]\n",
    "            conf = box.conf\n",
    "            track_id = str(int(box.id[0].tolist()))\n",
    "            if track_id not in track_ids:\n",
    "                track_ids.add(track_id)\n",
    "                count_classes[name] += 1\n",
    "            x1, y1, x2, y2 = [int(item) for item in bounding_box[0]]\n",
    "            plate, plate_conf, px1, py1, px2, py2, plate_text = \"\", \"\", \"\", \"\", \"\", \"\", \"\"\n",
    "            if name != \"person\":\n",
    "                vehicle_box = frame[y1:y2, x1:x2]\n",
    "                plates_result = our_model(vehicle_box, show=False)\n",
    "                if len(plates_result[0].boxes) > 0:\n",
    "                    plate_conf = plates_result[0].boxes.conf\n",
    "                    plate_detection = (plates_result[0].boxes.xyxy).tolist()\n",
    "                    px1, py1, px2, py2 = [int(item) for item in plate_detection[0]]\n",
    "                    plate = vehicle_box[py1:py2, px1:px2]\n",
    "                    real_x1 = px1+x1\n",
    "                    real_y1 = py1+y1\n",
    "                    real_x2 = px2+x1\n",
    "                    real_y2 = py2+y1\n",
    "                    cv2.rectangle(annotated_frame, (real_x1, real_y1), (real_x2, real_y2), (0, 255, 0), 2)\n",
    "                    plate_text = ocr_easy(plate, frame, real_x1, real_y1)\n",
    "                    plate_text = plate_text.strip()\n",
    "                    if plate_text is not None:\n",
    "                        show_plate_text = plate_text\n",
    "            save_csv.append([\"frame\", name, conf, track_id, x1, y1, x2, y2, \"plate\", plate_conf, px1, py1, px2, py2, plate_text])\n",
    "            if show_plate_text != last_plate:\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                (text_width, text_height), baseline = cv2.getTextSize(f\"Matrícula detectada: {show_plate_text}\", font, 0.8, 2)\n",
    "                text_x = (text_box_w - text_width) // 2\n",
    "                text_y = (text_box_h + text_height) // 2 - baseline\n",
    "                cv2.putText(annotated_frame, show_plate_text, (text_x, text_y), font, 0.8, (255, 255, 255), 2)\n",
    "                last_plate = show_plate_text\n",
    "            \n",
    "        out.write(annotated_frame)\n",
    "        \"\"\"cv2.imshow(\"Deteccion de YOLO\", annotated_frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == 27 or cv2.getWindowProperty(\"Deteccion de YOLO\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\"\"\"\n",
    "    else:\n",
    "        # El vídeo ya se terminó\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(count_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ca6f4",
   "metadata": {},
   "source": [
    "### Volcado de datos en archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11dceb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'resultados.csv' creado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "registros = [\n",
    "    [1, \"auto\", 0.92, 3, 120, 200, 360, 480, True, 0.88, 135, 215, 345, 465, \"ABC1234\"],\n",
    "    [1, \"moto\", 0.85, 5, 400, 220, 500, 380, False, 0.00, 0, 0, 0, 0, \"\"],\n",
    "    [2, \"auto\", 0.95, 3, 125, 205, 365, 485, True, 0.90, 140, 220, 350, 470, \"ABC1234\"],\n",
    "    [2, \"camioneta\", 0.88, 7, 600, 250, 900, 550, True, 0.75, 620, 270, 880, 530, \"XYZ9876\"],\n",
    "    [3, \"auto\", 0.93, 3, 130, 210, 370, 490, True, 0.85, 145, 225, 355, 475, \"ABC1234\"],\n",
    "    [3, \"moto\", 0.80, 5, 405, 225, 505, 385, False, 0.00, 0, 0, 0, 0, \"\"]\n",
    "]\n",
    "def data_to_csv(registros):\n",
    "    columnas = [\n",
    "        \"fotograma\", \"tipo_objeto\", \"confianza\", \"id_tracking\",\n",
    "        \"x1\", \"y1\", \"x2\", \"y2\",\n",
    "        \"matricula_detectada\", \"conf_ocr\",\n",
    "        \"mx1\", \"my1\", \"mx2\", \"my2\",\n",
    "        \"texto_matricula\"\n",
    "    ]\n",
    "\n",
    "    with open(\"resultados.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter=';')\n",
    "        writer.writerow(columnas)    \n",
    "        writer.writerows(registros)  \n",
    "\n",
    "    print(\"Archivo 'resultados.csv' creado correctamente.\")\n",
    "\n",
    "data_to_csv(registros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcb0c89",
   "metadata": {},
   "source": [
    "### Comparativa entre modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020de6a9",
   "metadata": {},
   "source": [
    "Métodos rediseñados para la comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfd1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_vlm_com(frame, x1, y1, x2, y2, processor, model, device=\"cuda\", max_new_tokens=15):\n",
    "\n",
    "\n",
    "    if isinstance(frame, np.ndarray):\n",
    "        frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    crop = frame.crop((x1, y1, x2, y2))\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": crop},\n",
    "                {\"type\": \"text\", \"text\": \"Can you give me the text in the license plate of the image?\"}\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(text=prompt, images=[crop], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "        vlm_output = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    text = vlm_output\n",
    "    if \"Assistant:\" in text:\n",
    "        text = text.split(\"Assistant:\")[-1]\n",
    "\n",
    "    parts = text.split()\n",
    "    plate_parts = [re.sub(r\"[^A-Z0-9]\", \"\", p.upper()) for p in parts if re.sub(r\"[^A-Z0-9]\", \"\", p.upper())]\n",
    "    license_plate = \"\".join(plate_parts)\n",
    "\n",
    "    return license_plate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1d2fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['es'], gpu=False)\n",
    "\n",
    "def ocr_easy_com(frame, x1, y1, x2, y2, escala=3):\n",
    "    placa_crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "    placa_crop = cv2.resize(placa_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    gray = cv2.cvtColor(placa_crop, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    gray = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)\n",
    "\n",
    "    results_ocr = reader.readtext(\n",
    "        gray,\n",
    "        allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
    "        detail=1\n",
    "    )\n",
    "\n",
    "    if not results_ocr:\n",
    "        return \"\"\n",
    "\n",
    "    results_sorted = sorted(results_ocr, key=lambda r: r[0][0][0])  # r[0][0][0] = x top-left\n",
    "    plate_parts = [text.strip().upper() for (_, text, _) in results_sorted]\n",
    "    license_plate = \"\".join(plate_parts)\n",
    "\n",
    "    return license_plate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d08b976",
   "metadata": {},
   "source": [
    "Código definitivo para la comparativa (ejecutado en Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d59981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm\n",
    "\n",
    "PATH = \"/kaggle/input/matriculas-comparativa\"\n",
    "OUR_MODEL_PATH = '/kaggle/input/best-pt/pytorch/yolo11n/1/best.pt'\n",
    "\n",
    "our_model = YOLO(OUR_MODEL_PATH)\n",
    "our_model.to('cuda')\n",
    "\n",
    "correct_vlm = 0\n",
    "correct_easy = 0\n",
    "time_vlm = 0.0\n",
    "time_easy = 0.0\n",
    "\n",
    "image_files = [\n",
    "    f for f in os.listdir(PATH)\n",
    "    if f.lower().endswith((\".jpg\", \".jpeg\"))\n",
    "]\n",
    "\n",
    "\n",
    "for img_name in tqdm(image_files, desc=\"Procesamiento de matrículas\"):\n",
    "    img_path = os.path.join(PATH, img_name)\n",
    "    label = os.path.splitext(img_name)[0].upper()\n",
    "\n",
    "    frame = cv2.imread(img_path)\n",
    "    if frame is None:\n",
    "        continue\n",
    "\n",
    "    result = our_model(frame, show=False)\n",
    "    plate = result[0].boxes.xyxy.tolist()\n",
    "    x1, y1, x2, y2 = [int(item) for item in plate[0]]\n",
    "\n",
    "    start = time.time()\n",
    "    try:\n",
    "        text_vlm = ocr_vlm_com(frame, x1, y1, x2, y2, processor, model, device=\"cuda\", max_new_tokens=15)\n",
    "    except Exception as e:\n",
    "        print(f\"[VLM error on {img_name}]: {e}\")\n",
    "        text_vlm = \"\"\n",
    "    time_vlm += time.time() - start\n",
    "    if text_vlm and text_vlm.strip().replace(\" \", \"\").upper() == label:\n",
    "        correct_vlm += 1\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    try:\n",
    "        text_easy = ocr_easy_com(frame, x1, y1, x2, y2)\n",
    "    except Exception as e:\n",
    "        print(f\"[EasyOCR error on {img_name}]: {e}\")\n",
    "        text_easy = \"\"\n",
    "    time_easy += time.time() - start\n",
    "    if text_easy and text_easy.strip().replace(\" \", \"\").upper() == label:\n",
    "        correct_easy += 1\n",
    "\n",
    "total = len(image_files)\n",
    "avg_time_vlm = time_vlm / total if total > 0 else 0\n",
    "avg_time_easy = time_easy / total if total > 0 else 0\n",
    "\n",
    "print(\"\\n=== COMPARATIVA DE MODELOS ===\")\n",
    "print(f\"Número de imágenes probadas: {total}\")\n",
    "print(f\"SmolVLM (aciertos): {correct_vlm} / {total} ({correct_vlm / total:.2%})\")\n",
    "print(f\"EasyOCR (aciertos): {correct_easy} / {total} ({correct_easy / total:.2%})\")\n",
    "\n",
    "print(\"\\n=== TIEMPO MEDIO DE INFERENCIA ===\")\n",
    "print(f\"SmolVLM: {avg_time_vlm:.3f} s/img\")\n",
    "print(f\"EasyOCR: {avg_time_easy:.3f} s/img\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
