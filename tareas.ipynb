{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64dbf540",
   "metadata": {},
   "source": [
    "Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc881425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import math \n",
    "\n",
    "from ultralytics import YOLO\n",
    "from matplotlib import pyplot as plt\n",
    "import easyocr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728c5aa",
   "metadata": {},
   "source": [
    "Extraemos las clases del modelo YOLO 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23885f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "vid = cv2.VideoCapture(\"C0142.MP4\")\n",
    "\n",
    "names = None\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if ret:\n",
    "        results = model(frame, show=False)\n",
    "        if names is None:\n",
    "            names = results[0].names\n",
    "        annotated_frame = results[0].plot()\n",
    "        cv2.imshow(\"Deteccion de YOLO\", annotated_frame)\n",
    "\n",
    "        # Salir del vídeo cuando presionamos ESC\n",
    "        if cv2.waitKey(1) & 0xFF == 27 or cv2.getWindowProperty(\"Deteccion de YOLO\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "    else:\n",
    "        # El vídeo ya se terminó\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Leemos las posibles clases\n",
    "with open(\"classes.txt\", \"w\") as f:\n",
    "    f.write(str(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d49077",
   "metadata": {},
   "source": [
    "### Mostramos el funcionamiento de nuestro modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('best.pt')\n",
    "\n",
    "vid = cv2.VideoCapture(\"C0142.MP4\")\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if ret:\n",
    "        results = model(frame, show=False)\n",
    "        annotated_frame = results[0].plot()\n",
    "        cv2.imshow(\"Deteccion de YOLO\", annotated_frame)\n",
    "\n",
    "        # Salir del vídeo cuando presionamos ESC\n",
    "        if cv2.waitKey(1) & 0xFF == 27 or cv2.getWindowProperty(\"Deteccion de YOLO\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "    else:\n",
    "        # El vídeo ya se terminó\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "971154ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31.28s] Matrícula: 271LC (Conf: 0.55)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO('best.pt')\n",
    "reader = easyocr.Reader(['es'])\n",
    "vid = cv2.VideoCapture(\"C0142.MP4\")\n",
    "\n",
    "if not vid.isOpened():\n",
    "    exit()\n",
    "\n",
    "frame_count = 0\n",
    "frame_skip = 3\n",
    "last_plate = None\n",
    "margin = 10  \n",
    "\n",
    "while True:\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    results = model(frame, verbose=False)\n",
    "    detections = results[0].boxes\n",
    "\n",
    "    for box in detections:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "        if frame_count % frame_skip == 0:\n",
    "            x1m = max(0, x1 - margin)\n",
    "            y1m = max(0, y1 - margin)\n",
    "            x2m = min(frame.shape[1], x2 + margin)\n",
    "            y2m = min(frame.shape[0], y2 + margin)\n",
    "            placa_crop = frame[y1m:y2m, x1m:x2m]\n",
    "\n",
    "            if placa_crop.size > 0:\n",
    "                escala = 3\n",
    "                placa_crop = cv2.resize(placa_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "                gray = cv2.cvtColor(placa_crop, cv2.COLOR_BGR2GRAY)\n",
    "                gray = cv2.equalizeHist(gray)\n",
    "                gray = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)\n",
    "\n",
    "                ocr_result = reader.readtext(\n",
    "                    gray,\n",
    "                    allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
    "                    detail=1\n",
    "                )\n",
    "\n",
    "                if len(ocr_result) > 0:\n",
    "                    text = ocr_result[0][1].strip()\n",
    "                    prob = ocr_result[0][2]\n",
    "\n",
    "                    if len(text) >= 4 and prob > 0.5 and text != last_plate:\n",
    "                        last_plate = text\n",
    "                        timestamp = vid.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "                        print(f\"[{timestamp:.2f}s] Matrícula: {text} (Conf: {prob:.2f})\")\n",
    "                        cv2.putText(frame, f'{text}', (x1, y1 - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"Detección + OCR\", frame)\n",
    "    if cv2.waitKey(30) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b0a81a",
   "metadata": {},
   "source": [
    "### Usamos el modelo pre-entrenado de YOLO y el nuestro en conjunto \n",
    "Utilizamos el modelo pre-entrenado para detectar personas y vehículos, posteriormente, cuando hayamos detectado un vehículo, se lo pasamos a nuestro modelo entrenado en matrículas para que le detecte la matrícula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = YOLO('yolo11n.pt')\n",
    "our_model = YOLO('best.pt')\n",
    "vid = cv2.VideoCapture(\"prueba_coches.mp4\")\n",
    "\n",
    "frame_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "output_path = 'resultados.mp4'\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "def ocr(placa_crop, last_plate=None):\n",
    "    escala = 3\n",
    "    placa_crop = cv2.resize(placa_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    gray = cv2.cvtColor(placa_crop, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    gray = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)\n",
    "\n",
    "    ocr_result = reader.readtext(\n",
    "        gray,\n",
    "        allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
    "        detail=1\n",
    "    )\n",
    "\n",
    "    text = \"\"\n",
    "\n",
    "    if len(ocr_result) > 0:\n",
    "        text = ocr_result[0][1].strip()\n",
    "        prob = ocr_result[0][2]\n",
    "\n",
    "        if len(text) >= 4 and prob > 0.5 and text != last_plate:\n",
    "            last_plate = text\n",
    "            timestamp = vid.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "            print(f\"[{timestamp:.2f}s] Matrícula: {text} (Conf: {prob:.2f})\")\n",
    "            cv2.putText(frame, f'{text}', (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    return text\n",
    "\n",
    "reader = easyocr.Reader(['es'], gpu=False) \n",
    "\n",
    "classes = [0, 2, 3, 5, 7]    # Person, car, motorcycle, bus, truck\n",
    "\n",
    "car_boxes = []\n",
    "car_boxes_left_coords = []\n",
    "\n",
    "save_csv = []\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if ret:\n",
    "        base_results = base_model.track(frame, persist=True, show=False, classes=classes)\n",
    "        plates_result = None\n",
    "        annotated_frame = base_results[0].plot()\n",
    "        boxes = list()\n",
    "        for result in base_results:\n",
    "            boxes += result.boxes\n",
    "        for box in boxes:\n",
    "            bounding_box = box.xyxy.tolist()\n",
    "            name = result[0].names[box.cls.int().item()]\n",
    "            conf = box.conf\n",
    "            track_id = str(int(box.id[0].tolist()))\n",
    "            x1, y1, x2, y2 = [int(item) for item in bounding_box[0]]\n",
    "            plate, plate_conf, px1, py1, px2, py2, plate_text = \"\", \"\", \"\", \"\", \"\", \"\", \"\"\n",
    "            if name != \"person\":\n",
    "                vehicle_box = frame[y1:y2, x1:x2]\n",
    "                plates_result = our_model(vehicle_box, show=False)\n",
    "                if len(plates_result[0].boxes) > 0:\n",
    "                    plate_conf = plates_result[0].boxes.conf\n",
    "                    plate_detection = (plates_result[0].boxes.xyxy).tolist()\n",
    "                    px1, py1, px2, py2 = [int(item) for item in plate_detection[0]]\n",
    "                    plate = vehicle_box[py1:py2, px1:px2]\n",
    "                    real_x1 = px1+x1\n",
    "                    real_y1 = py1+y1\n",
    "                    real_x2 = px2+x1\n",
    "                    real_y2 = py2+y1\n",
    "                    plate_text = ocr(plate)\n",
    "                    cv2.rectangle(annotated_frame, (real_x1, real_y1), (real_x2, real_y2), (0, 255, 0), 1)\n",
    "            save_csv.append([frame, name, conf, track_id, x1, y1, x2, y2, plate, plate_conf, px1, py1, px2, py2, plate_text])\n",
    "                        \n",
    "        out.write(annotated_frame)\n",
    "    else:\n",
    "        # El vídeo ya se terminó\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# fotograma, tipo_objeto, confianza, identificador_tracking, x1, y1, x2, y2, matrícula_en_su_caso, confianza, mx1,my1,mx2,my2, texto_matricula\n",
    "print(save_csv)\n",
    "\n",
    "# Mostrar el total de cada clase\n",
    "count_classes = {\"person\": 0, \"car\": 0, \"motorcycle\": 0, \"bus\": 0, \"truck\": 0}\n",
    "for row in save_csv:\n",
    "    for c in count_classes.keys(): \n",
    "        if c in row[1]:\n",
    "            count_classes[c] += 1\n",
    "print(count_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5393f7c2",
   "metadata": {},
   "source": [
    "Opción 2 (por si hace falta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76680639",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_results = base_model(frame, show=False, classes=classes)\n",
    "plates_result = None\n",
    "annotated_frame = base_results[0].plot()\n",
    "for box in result.boxes:\n",
    "    if result.names[int(box.cls)] != \"person\":\n",
    "        x1, y1, x2, y2 = box.xyxy[0].int().tolist()\n",
    "        car_boxes.append(frame[y1:y2, x1:x2])\n",
    "        car_boxes_left_coords.append((x1, y1))\n",
    "if car_boxes:\n",
    "    plates_results = our_model(car_boxes, show=False)\n",
    "    for i, plates_result in enumerate(plates_results):\n",
    "        car_x, car_y = car_boxes_left_coords[i]\n",
    "        if len(plates_result.boxes) > 0:\n",
    "            px1, py1, px2, py2 = plates_result.boxes[0].xyxy[0].int().tolist()\n",
    "            real_x1 = px1 + car_x\n",
    "            real_y1 = py1 + car_y\n",
    "            real_x2 = px2 + car_x\n",
    "            real_y2 = py2 + car_y\n",
    "            cv2.rectangle(annotated_frame, (real_x1, real_y1), (real_x2, real_y2), (0, 255, 0), 3)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ca6f4",
   "metadata": {},
   "source": [
    "Pruebas OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b308e6",
   "metadata": {},
   "source": [
    "#### Easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb0b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "from IPython.display import Video, display\n",
    "import os\n",
    "\n",
    "\n",
    "model_path = \"best.pt\"\n",
    "video_path = \"C0142.MP4\"\n",
    "crop_dir   = \"crops/\"  \n",
    "os.makedirs(crop_dir, exist_ok=True)\n",
    "\n",
    "model = YOLO(model_path)\n",
    "reader = easyocr.Reader(['en'], gpu=True)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise Exception(f\"No se pudo abrir el vídeo: {video_path}\")\n",
    "\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps_in = cap.get(cv2.CAP_PROP_FPS) or 20.0\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('resultado.mp4', fourcc, fps_in, (width, height))\n",
    "\n",
    "margin = 10\n",
    "frame_count = 0\n",
    "last_texts = set()\n",
    "\n",
    "def preprocess_for_ocr(img_crop, escala=4):\n",
    "\n",
    "    img = cv2.resize(img_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray_blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray_blur,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        13,\n",
    "        2\n",
    "    )\n",
    "\n",
    "    return thresh\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "\n",
    "    results = model(frame, verbose=False)\n",
    "    detections = results[0].boxes\n",
    "\n",
    "    for box in detections:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        conf = float(box.conf[0])\n",
    "        if conf < 0.2:\n",
    "            continue\n",
    "\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        extra = int(max(w, h) * 0.15)\n",
    "        x1m = max(0, x1 - margin - extra)\n",
    "        y1m = max(0, y1 - margin - extra)\n",
    "        x2m = min(frame.shape[1], x2 + margin + extra)\n",
    "        y2m = min(frame.shape[0], y2 + margin + extra)\n",
    "\n",
    "        placa_crop = frame[y1m:y2m, x1m:x2m]\n",
    "\n",
    "        if placa_crop.size > 0:\n",
    "\n",
    "            gray = preprocess_for_ocr(placa_crop)\n",
    "\n",
    "            ocr_result = reader.readtext(\n",
    "                gray,\n",
    "                allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
    "                detail=1,\n",
    "                text_threshold=0.2\n",
    "            )\n",
    "\n",
    "            if len(ocr_result) > 0:\n",
    "                for (bbox, text, prob) in ocr_result:\n",
    "                    text_clean = text.strip().replace(\" \", \"\")\n",
    "                    if prob > 0.7 and len(text_clean) >= 7 and text_clean not in last_texts:\n",
    "                        last_texts.add(text_clean)\n",
    "                        timestamp = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "\n",
    "                        print(f\"[{timestamp:.2f}s] Matrícula detectada: {text_clean} (Conf: {prob:.2f})\")\n",
    "\n",
    "                        cv2.putText(frame, text_clean, (x1, y1 - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                        crop_filename = os.path.join(crop_dir, f\"{text_clean}_{frame_count}.jpg\")\n",
    "                        cv2.imwrite(crop_filename, gray)\n",
    "                        print(f\"Guardada imagen: {crop_filename}\")\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Procesamiento completado. Total frames: {frame_count}\")\n",
    "display(Video('resultado.mp4', embed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c874d4",
   "metadata": {},
   "source": [
    "#### Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "from IPython.display import Video, display\n",
    "import os\n",
    "\n",
    "# Configura la ruta si Tesseract no está en PATH\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "model_path = \"best.pt\"\n",
    "video_path = \"C0142.MP4\"\n",
    "crop_dir   = \"crops/\"  \n",
    "os.makedirs(crop_dir, exist_ok=True)\n",
    "\n",
    "model = YOLO(model_path)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise Exception(f\"No se pudo abrir el vídeo: {video_path}\")\n",
    "\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps_in = cap.get(cv2.CAP_PROP_FPS) or 20.0\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('resultado_tesseract.mp4', fourcc, fps_in, (width, height))\n",
    "\n",
    "margin = 10\n",
    "frame_count = 0\n",
    "last_texts = set()\n",
    "\n",
    "def preprocess_for_ocr(img_crop, escala=4):\n",
    "    # Escala y convierte a gris\n",
    "    img = cv2.resize(img_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    # Umbral adaptativo\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray_blur,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        13,\n",
    "        2\n",
    "    )\n",
    "    return thresh\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "\n",
    "    results = model(frame, verbose=False)\n",
    "    detections = results[0].boxes\n",
    "\n",
    "    for box in detections:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        conf = float(box.conf[0])\n",
    "        if conf < 0.2:\n",
    "            continue\n",
    "\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        extra = int(max(w, h) * 0.15)\n",
    "        x1m = max(0, x1 - margin - extra)\n",
    "        y1m = max(0, y1 - margin - extra)\n",
    "        x2m = min(frame.shape[1], x2 + margin + extra)\n",
    "        y2m = min(frame.shape[0], y2 + margin + extra)\n",
    "\n",
    "        placa_crop = frame[y1m:y2m, x1m:x2m]\n",
    "\n",
    "        if placa_crop.size > 0:\n",
    "            gray = preprocess_for_ocr(placa_crop)\n",
    "\n",
    "            # Usando Tesseract\n",
    "            ocr_result = pytesseract.image_to_data(\n",
    "                gray,\n",
    "                output_type=Output.DICT,\n",
    "                config='--psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
    "            )\n",
    "\n",
    "            n_boxes = len(ocr_result['text'])\n",
    "            for i in range(n_boxes):\n",
    "                text = ocr_result['text'][i].strip().replace(\" \", \"\")\n",
    "                conf = float(ocr_result['conf'][i])\n",
    "                if len(text) >= 7 and conf > 60 and text not in last_texts:\n",
    "                    last_texts.add(text)\n",
    "                    timestamp = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "                    print(f\"[{timestamp:.2f}s] Matrícula detectada: {text} (Conf: {conf:.2f})\")\n",
    "\n",
    "                    cv2.putText(frame, text, (x1, y1 - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                    crop_filename = os.path.join(crop_dir, f\"{text}_{frame_count}.jpg\")\n",
    "                    cv2.imwrite(crop_filename, gray)\n",
    "                    print(f\"Guardada imagen: {crop_filename}\")\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Procesamiento completado. Total frames: {frame_count}\")\n",
    "display(Video('resultado_tesseract.mp4', embed=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11dceb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'resultados.csv' creado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "registros = [\n",
    "    [1, \"auto\", 0.92, 3, 120, 200, 360, 480, True, 0.88, 135, 215, 345, 465, \"ABC1234\"],\n",
    "    [1, \"moto\", 0.85, 5, 400, 220, 500, 380, False, 0.00, 0, 0, 0, 0, \"\"],\n",
    "    [2, \"auto\", 0.95, 3, 125, 205, 365, 485, True, 0.90, 140, 220, 350, 470, \"ABC1234\"],\n",
    "    [2, \"camioneta\", 0.88, 7, 600, 250, 900, 550, True, 0.75, 620, 270, 880, 530, \"XYZ9876\"],\n",
    "    [3, \"auto\", 0.93, 3, 130, 210, 370, 490, True, 0.85, 145, 225, 355, 475, \"ABC1234\"],\n",
    "    [3, \"moto\", 0.80, 5, 405, 225, 505, 385, False, 0.00, 0, 0, 0, 0, \"\"]\n",
    "]\n",
    "def data_to_csv(registros):\n",
    "    columnas = [\n",
    "        \"fotograma\", \"tipo_objeto\", \"confianza\", \"id_tracking\",\n",
    "        \"x1\", \"y1\", \"x2\", \"y2\",\n",
    "        \"matricula_detectada\", \"conf_ocr\",\n",
    "        \"mx1\", \"my1\", \"mx2\", \"my2\",\n",
    "        \"texto_matricula\"\n",
    "    ]\n",
    "\n",
    "    with open(\"resultados.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter=';')\n",
    "        writer.writerow(columnas)    \n",
    "        writer.writerows(registros)  \n",
    "\n",
    "    print(\"Archivo 'resultados.csv' creado correctamente.\")\n",
    "\n",
    "data_to_csv(registros)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
