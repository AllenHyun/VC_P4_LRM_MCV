{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64dbf540",
   "metadata": {},
   "source": [
    "Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc881425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lllrm\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import Video, display\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728c5aa",
   "metadata": {},
   "source": [
    "Extraemos las clases del modelo YOLO 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23885f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "vid = cv2.VideoCapture(\"C0142.MP4\")\n",
    "\n",
    "names = None\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if ret:\n",
    "        results = model(frame, show=False)\n",
    "        if names is None:\n",
    "            names = results[0].names\n",
    "        annotated_frame = results[0].plot()\n",
    "        cv2.imshow(\"Deteccion de YOLO\", annotated_frame)\n",
    "\n",
    "        # Salir del vídeo cuando presionamos ESC\n",
    "        if cv2.waitKey(1) & 0xFF == 27 or cv2.getWindowProperty(\"Deteccion de YOLO\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "    else:\n",
    "        # El vídeo ya se terminó\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Leemos las posibles clases\n",
    "with open(\"classes.txt\", \"w\") as f:\n",
    "    f.write(str(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d49077",
   "metadata": {},
   "source": [
    "### Mostramos el funcionamiento de nuestro modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('best.pt')\n",
    "\n",
    "vid = cv2.VideoCapture(\"C0142.MP4\")\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if ret:\n",
    "        results = model(frame, show=False)\n",
    "        annotated_frame = results[0].plot()\n",
    "        cv2.imshow(\"Deteccion de YOLO\", annotated_frame)\n",
    "\n",
    "        # Salir del vídeo cuando presionamos ESC\n",
    "        if cv2.waitKey(1) & 0xFF == 27 or cv2.getWindowProperty(\"Deteccion de YOLO\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "    else:\n",
    "        # El vídeo ya se terminó\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b0a81a",
   "metadata": {},
   "source": [
    "### Usamos el modelo pre-entrenado de YOLO y el nuestro en conjunto \n",
    "Utilizamos el modelo pre-entrenado para detectar personas y vehículos, posteriormente, cuando hayamos detectado un vehículo, se lo pasamos a nuestro modelo entrenado en matrículas para que le detecte la matrícula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d241ad",
   "metadata": {},
   "source": [
    "Código para las detecciones de OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código necesario para el VLM\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "import torch\n",
    "device = \"cpu\"  # or \"cpu\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-Instruct\")\n",
    "model = AutoModelForImageTextToText.from_pretrained(\"HuggingFaceTB/SmolVLM-Instruct\",\n",
    "                                                dtype=torch.bfloat16,\n",
    "                                                _attn_implementation=\"flash_attention_2\" if device == \"cuda\" else \"eager\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69c034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Solo se está usando en el Tesseract (Se elimina?)\n",
    "def preprocess_for_ocr(img_crop, escala=4):\n",
    "\n",
    "    img = cv2.resize(img_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray_blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray_blur,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        13,\n",
    "        2\n",
    "    )\n",
    "\n",
    "    return thresh\n",
    "\n",
    "reader = easyocr.Reader(['es'], gpu=False) \n",
    "\n",
    "def ocr_easy(placa_crop, frame, x1, y1, last_plate=None):\n",
    "    escala = 3\n",
    "    placa_crop = cv2.resize(placa_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    gray = cv2.cvtColor(placa_crop, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    gray = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)\n",
    "\n",
    "    ocr_result = reader.readtext(\n",
    "        gray,\n",
    "        allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
    "        detail=1\n",
    "    )\n",
    "\n",
    "    text = \"\"\n",
    "\n",
    "    if len(ocr_result) > 0:\n",
    "        text = ocr_result[0][1].strip()\n",
    "        prob = ocr_result[0][2]\n",
    "\n",
    "        if len(text) >= 4 and prob > 0.5 and text != last_plate:\n",
    "            last_plate = text\n",
    "            timestamp = vid.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "            plate_pattern = re.compile(\"^[0-9]{4}[BCDFGHJKLMNPRSTVWXYZ]{3}$\")\n",
    "            if plate_pattern.match(text.strip()):\n",
    "                print(f\"[{timestamp:.2f}s] Matrícula: {text} (Conf: {prob:.2f})\")\n",
    "                cv2.putText(frame, f'{text}', (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                return\n",
    "   \n",
    "        return text\n",
    "\n",
    "def ocr_vlm(crop, frame, x1, y1, x2, y2):\n",
    "    plate_img = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": \"Read the text on this license plate.\"}\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(text=prompt, images=[plate_img], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=10)\n",
    "        generated_texts = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        plate_text = generated_texts[0].strip()\n",
    "\n",
    "        if \"Assistant: \" in plate_text:\n",
    "            raw_text = plate_text.split(\"Assistant: \")[1]\n",
    "        else:\n",
    "            plate_text = raw_text\n",
    "\n",
    "    plate_pattern = re.compile(\"^[0-9]{4}[BCDFGHJKLMNPRSTVWXYZ]{3}$\")\n",
    "    if plate_pattern.match(plate_text.strip()):\n",
    "        cv2.putText(frame, raw_text, (x1, max(30, y1 - 10)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    return raw_text\n",
    "\n",
    "# NO SE USA (Lo eliminamos cuando esté confirmado que usamos los otros dos)\n",
    "def ocr_tesseract(placa_crop, frame_count, cap, crop_dir=\"crops/\", last_texts=set()):\n",
    "    if placa_crop.size > 0:\n",
    "        gray = preprocess_for_ocr(placa_crop)\n",
    "\n",
    "        # Usando Tesseract\n",
    "        ocr_result = pytesseract.image_to_data(\n",
    "            gray,\n",
    "            output_type=Output.DICT,\n",
    "            config='--psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
    "        )\n",
    "\n",
    "        n_boxes = len(ocr_result['text'])\n",
    "        for i in range(n_boxes):\n",
    "            text = ocr_result['text'][i].strip().replace(\" \", \"\")\n",
    "            conf = float(ocr_result['conf'][i])\n",
    "            if len(text) >= 7 and conf > 60 and text not in last_texts:\n",
    "                last_texts.add(text)\n",
    "                timestamp = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "                print(f\"[{timestamp:.2f}s] Matrícula detectada: {text} (Conf: {conf:.2f})\")\n",
    "\n",
    "                cv2.putText(frame, text, (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                crop_filename = os.path.join(crop_dir, f\"{text}_{frame_count}.jpg\")\n",
    "                cv2.imwrite(crop_filename, gray)\n",
    "                print(f\"Guardada imagen: {crop_filename}\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e835c4b",
   "metadata": {},
   "source": [
    "Código principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_MODEL_PATH = 'yolo11n.pt'\n",
    "OUR_MODEL_PATH = 'best.pt'\n",
    "\n",
    "VIDEO_PATH = \"prueba_coches.mp4\"\n",
    "base_model = YOLO(BASE_MODEL_PATH)\n",
    "our_model = YOLO(OUR_MODEL_PATH)\n",
    "vid = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "frame_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "output_path = 'resultados.mp4'\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "def data_to_csv(registros):\n",
    "    columnas = [\n",
    "        \"fotograma\", \"tipo_objeto\", \"confianza\", \"id_tracking\",\n",
    "        \"x1\", \"y1\", \"x2\", \"y2\",\n",
    "        \"matricula_detectada\", \"conf_ocr\",\n",
    "        \"mx1\", \"my1\", \"mx2\", \"my2\",\n",
    "        \"texto_matricula\"\n",
    "    ]\n",
    "\n",
    "    with open(\"resultados.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter=';')\n",
    "        writer.writerow(columnas)    \n",
    "        writer.writerows(registros)  \n",
    "\n",
    "    print(\"Archivo 'resultados.csv' creado correctamente.\")\n",
    "\n",
    "\n",
    "classes = [0, 2, 3, 5, 7]    # Person, car, motorcycle, bus, truck\n",
    "\n",
    "car_boxes = []\n",
    "car_boxes_left_coords = []\n",
    "\n",
    "track_ids = set()\n",
    "count_classes = {\"person\": 0, \"car\": 0, \"motorcycle\": 0, \"bus\": 0, \"truck\": 0}\n",
    "\n",
    "save_csv = []\n",
    "frame_count = 0\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    frame_count += 1\n",
    "\n",
    "    if ret:\n",
    "        base_results = base_model.track(frame, persist=True, show=False, classes=classes)\n",
    "        plates_result = None\n",
    "        annotated_frame = base_results[0].plot()\n",
    "        boxes = list()\n",
    "\n",
    "        # Mostramos un recuadro arriba a la izquierda que muestre las matrículas que se vayan detectando\n",
    "        text_box_w = int(frame.shape[1]*0.2)\n",
    "        text_box_h = int(frame.shape[0]*0.09)\n",
    "        \n",
    "        cv2.rectangle(annotated_frame, (0, 0), (text_box_w, text_box_h), (0, 0, 0), -1)\n",
    "\n",
    "        last_plate = \"\"\n",
    "        show_plate_text = \"\"\n",
    "        \n",
    "        for result in base_results:\n",
    "            boxes += result.boxes\n",
    "        for box in boxes:\n",
    "            bounding_box = box.xyxy.tolist()\n",
    "            name = result[0].names[box.cls.int().item()]\n",
    "            conf = box.conf\n",
    "            track_id = str(int(box.id[0].tolist()))\n",
    "            if track_id not in track_ids:\n",
    "                track_ids.add(track_id)\n",
    "                count_classes[name] += 1\n",
    "            x1, y1, x2, y2 = [int(item) for item in bounding_box[0]]\n",
    "            plate, plate_conf, px1, py1, px2, py2, plate_text = \"\", \"\", \"\", \"\", \"\", \"\", \"\"\n",
    "            if name != \"person\":\n",
    "                vehicle_box = frame[y1:y2, x1:x2]\n",
    "                plates_result = our_model(vehicle_box, show=False)\n",
    "                if len(plates_result[0].boxes) > 0:\n",
    "                    plate_conf = plates_result[0].boxes.conf\n",
    "                    plate_detection = (plates_result[0].boxes.xyxy).tolist()\n",
    "                    px1, py1, px2, py2 = [int(item) for item in plate_detection[0]]\n",
    "                    plate = vehicle_box[py1:py2, px1:px2]\n",
    "                    real_x1 = px1+x1\n",
    "                    real_y1 = py1+y1\n",
    "                    real_x2 = px2+x1\n",
    "                    real_y2 = py2+y1\n",
    "                    cv2.rectangle(annotated_frame, (real_x1, real_y1), (real_x2, real_y2), (0, 255, 0), 2)\n",
    "                    plate_text = ocr_easy(plate, frame, real_x1, real_y1)\n",
    "                    plate_text = plate_text.strip()\n",
    "                    if plate_text is not None:\n",
    "                        show_plate_text = plate_text\n",
    "            save_csv.append([\"frame\", name, conf, track_id, x1, y1, x2, y2, \"plate\", plate_conf, px1, py1, px2, py2, plate_text])\n",
    "            if show_plate_text != last_plate:\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                (text_width, text_height), baseline = cv2.getTextSize(plate_text, font, 0.8, 2)\n",
    "                text_x = (text_box_w - text_width) // 2\n",
    "                text_y = (text_box_h + text_height) // 2 - baseline\n",
    "                cv2.putText(annotated_frame, plate_text, (text_x, text_y), font, 0.8, (255, 255, 255), 2)\n",
    "                last_plate = show_plate_text               \n",
    "            \n",
    "        out.write(annotated_frame)\n",
    "        \"\"\"cv2.imshow(\"Deteccion de YOLO\", annotated_frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == 27 or cv2.getWindowProperty(\"Deteccion de YOLO\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\"\"\"\n",
    "    else:\n",
    "        # El vídeo ya se terminó\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# fotograma, tipo_objeto, confianza, identificador_tracking, x1, y1, x2, y2, matrícula_en_su_caso, confianza, mx1,my1,mx2,my2, texto_matricula\n",
    "print(save_csv)\n",
    "print(count_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ca6f4",
   "metadata": {},
   "source": [
    "### Pruebas OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b308e6",
   "metadata": {},
   "source": [
    "#### Easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb0b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "from IPython.display import Video, display\n",
    "import os\n",
    "\n",
    "\n",
    "model_path = \"best.pt\"\n",
    "video_path = \"C0142.MP4\"\n",
    "crop_dir   = \"crops/\"  \n",
    "os.makedirs(crop_dir, exist_ok=True)\n",
    "\n",
    "model = YOLO(model_path)\n",
    "reader = easyocr.Reader(['en'], gpu=True)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise Exception(f\"No se pudo abrir el vídeo: {video_path}\")\n",
    "\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps_in = cap.get(cv2.CAP_PROP_FPS) or 20.0\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('resultado.mp4', fourcc, fps_in, (width, height))\n",
    "\n",
    "margin = 10\n",
    "frame_count = 0\n",
    "last_texts = set()\n",
    "\n",
    "def preprocess_for_ocr(img_crop, escala=4):\n",
    "\n",
    "    img = cv2.resize(img_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray_blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray_blur,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        13,\n",
    "        2\n",
    "    )\n",
    "\n",
    "    return thresh\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "\n",
    "    results = model(frame, verbose=False)\n",
    "    detections = results[0].boxes\n",
    "\n",
    "    for box in detections:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        conf = float(box.conf[0])\n",
    "        if conf < 0.2:\n",
    "            continue\n",
    "\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        extra = int(max(w, h) * 0.15)\n",
    "        x1m = max(0, x1 - margin - extra)\n",
    "        y1m = max(0, y1 - margin - extra)\n",
    "        x2m = min(frame.shape[1], x2 + margin + extra)\n",
    "        y2m = min(frame.shape[0], y2 + margin + extra)\n",
    "\n",
    "        placa_crop = frame[y1m:y2m, x1m:x2m]\n",
    "\n",
    "        if placa_crop.size > 0:\n",
    "\n",
    "            gray = preprocess_for_ocr(placa_crop)\n",
    "\n",
    "            ocr_result = reader.readtext(\n",
    "                gray,\n",
    "                allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
    "                detail=1,\n",
    "                text_threshold=0.2\n",
    "            )\n",
    "\n",
    "            if len(ocr_result) > 0:\n",
    "                for (bbox, text, prob) in ocr_result:\n",
    "                    text_clean = text.strip().replace(\" \", \"\")\n",
    "                    if prob > 0.7 and len(text_clean) >= 7 and text_clean not in last_texts:\n",
    "                        last_texts.add(text_clean)\n",
    "                        timestamp = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "\n",
    "                        print(f\"[{timestamp:.2f}s] Matrícula detectada: {text_clean} (Conf: {prob:.2f})\")\n",
    "\n",
    "                        cv2.putText(frame, text_clean, (x1, y1 - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                        crop_filename = os.path.join(crop_dir, f\"{text_clean}_{frame_count}.jpg\")\n",
    "                        cv2.imwrite(crop_filename, gray)\n",
    "                        print(f\"Guardada imagen: {crop_filename}\")\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Procesamiento completado. Total frames: {frame_count}\")\n",
    "display(Video('resultado.mp4', embed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c874d4",
   "metadata": {},
   "source": [
    "#### Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "from IPython.display import Video, display\n",
    "import os\n",
    "\n",
    "# Configura la ruta si Tesseract no está en PATH\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "model_path = \"best.pt\"\n",
    "video_path = \"C0142.MP4\"\n",
    "crop_dir   = \"crops/\"  \n",
    "os.makedirs(crop_dir, exist_ok=True)\n",
    "\n",
    "model = YOLO(model_path)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise Exception(f\"No se pudo abrir el vídeo: {video_path}\")\n",
    "\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps_in = cap.get(cv2.CAP_PROP_FPS) or 20.0\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('resultado_tesseract.mp4', fourcc, fps_in, (width, height))\n",
    "\n",
    "margin = 10\n",
    "frame_count = 0\n",
    "last_texts = set()\n",
    "\n",
    "def preprocess_for_ocr(img_crop, escala=4):\n",
    "    # Escala y convierte a gris\n",
    "    img = cv2.resize(img_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    # Umbral adaptativo\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray_blur,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        13,\n",
    "        2\n",
    "    )\n",
    "    return thresh\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "\n",
    "    results = model(frame, verbose=False)\n",
    "    detections = results[0].boxes\n",
    "\n",
    "    for box in detections:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        conf = float(box.conf[0])\n",
    "        if conf < 0.2:\n",
    "            continue\n",
    "\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        extra = int(max(w, h) * 0.15)\n",
    "        x1m = max(0, x1 - margin - extra)\n",
    "        y1m = max(0, y1 - margin - extra)\n",
    "        x2m = min(frame.shape[1], x2 + margin + extra)\n",
    "        y2m = min(frame.shape[0], y2 + margin + extra)\n",
    "\n",
    "        placa_crop = frame[y1m:y2m, x1m:x2m]\n",
    "\n",
    "        if placa_crop.size > 0:\n",
    "            gray = preprocess_for_ocr(placa_crop)\n",
    "\n",
    "            # Usando Tesseract\n",
    "            ocr_result = pytesseract.image_to_data(\n",
    "                gray,\n",
    "                output_type=Output.DICT,\n",
    "                config='--psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
    "            )\n",
    "\n",
    "            n_boxes = len(ocr_result['text'])\n",
    "            for i in range(n_boxes):\n",
    "                text = ocr_result['text'][i].strip().replace(\" \", \"\")\n",
    "                conf = float(ocr_result['conf'][i])\n",
    "                if len(text) >= 7 and conf > 60 and text not in last_texts:\n",
    "                    last_texts.add(text)\n",
    "                    timestamp = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "                    print(f\"[{timestamp:.2f}s] Matrícula detectada: {text} (Conf: {conf:.2f})\")\n",
    "\n",
    "                    cv2.putText(frame, text, (x1, y1 - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                    crop_filename = os.path.join(crop_dir, f\"{text}_{frame_count}.jpg\")\n",
    "                    cv2.imwrite(crop_filename, gray)\n",
    "                    print(f\"Guardada imagen: {crop_filename}\")\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Procesamiento completado. Total frames: {frame_count}\")\n",
    "display(Video('resultado_tesseract.mp4', embed=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11dceb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'resultados.csv' creado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "registros = [\n",
    "    [1, \"auto\", 0.92, 3, 120, 200, 360, 480, True, 0.88, 135, 215, 345, 465, \"ABC1234\"],\n",
    "    [1, \"moto\", 0.85, 5, 400, 220, 500, 380, False, 0.00, 0, 0, 0, 0, \"\"],\n",
    "    [2, \"auto\", 0.95, 3, 125, 205, 365, 485, True, 0.90, 140, 220, 350, 470, \"ABC1234\"],\n",
    "    [2, \"camioneta\", 0.88, 7, 600, 250, 900, 550, True, 0.75, 620, 270, 880, 530, \"XYZ9876\"],\n",
    "    [3, \"auto\", 0.93, 3, 130, 210, 370, 490, True, 0.85, 145, 225, 355, 475, \"ABC1234\"],\n",
    "    [3, \"moto\", 0.80, 5, 405, 225, 505, 385, False, 0.00, 0, 0, 0, 0, \"\"]\n",
    "]\n",
    "def data_to_csv(registros):\n",
    "    columnas = [\n",
    "        \"fotograma\", \"tipo_objeto\", \"confianza\", \"id_tracking\",\n",
    "        \"x1\", \"y1\", \"x2\", \"y2\",\n",
    "        \"matricula_detectada\", \"conf_ocr\",\n",
    "        \"mx1\", \"my1\", \"mx2\", \"my2\",\n",
    "        \"texto_matricula\"\n",
    "    ]\n",
    "\n",
    "    with open(\"resultados.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter=';')\n",
    "        writer.writerow(columnas)    \n",
    "        writer.writerows(registros)  \n",
    "\n",
    "    print(\"Archivo 'resultados.csv' creado correctamente.\")\n",
    "\n",
    "data_to_csv(registros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcb0c89",
   "metadata": {},
   "source": [
    "### Comparativa entre modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d59981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# Initialize OCR models\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"roboflow_labels.csv\")  # or your path\n",
    "df['ocr_tesseract'] = \"\"\n",
    "df['ocr_easyocr'] = \"\"\n",
    "\n",
    "# Process each image\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    img_path = row['image_path']\n",
    "    gt = row['label']\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    # Tesseract OCR\n",
    "    df.at[i, 'ocr_tesseract'] = pytesseract.image_to_string(img).strip().replace(\" \", \"\").upper()\n",
    "\n",
    "    # EasyOCR\n",
    "    result = reader.readtext(img)\n",
    "    text_easy = \"\".join([res[1] for res in result]).strip().replace(\" \", \"\").upper()\n",
    "    df.at[i, 'ocr_easyocr'] = text_easy\n",
    "\n",
    "# Save results\n",
    "df.to_csv(\"ocr_results.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
