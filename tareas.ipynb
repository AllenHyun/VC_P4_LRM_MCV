{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64dbf540",
   "metadata": {},
   "source": [
    "Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc881425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lllrm\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import Video, display\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728c5aa",
   "metadata": {},
   "source": [
    "Extraemos las clases del modelo YOLO 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23885f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "vid = cv2.VideoCapture(\"C0142.MP4\")\n",
    "\n",
    "names = None\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if ret:\n",
    "        results = model(frame, show=False)\n",
    "        if names is None:\n",
    "            names = results[0].names\n",
    "        annotated_frame = results[0].plot()\n",
    "        cv2.imshow(\"Deteccion de YOLO\", annotated_frame)\n",
    "\n",
    "        # Salir del vídeo cuando presionamos ESC\n",
    "        if cv2.waitKey(1) & 0xFF == 27 or cv2.getWindowProperty(\"Deteccion de YOLO\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "    else:\n",
    "        # El vídeo ya se terminó\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Leemos las posibles clases\n",
    "with open(\"classes.txt\", \"w\") as f:\n",
    "    f.write(str(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d49077",
   "metadata": {},
   "source": [
    "### Mostramos el funcionamiento de nuestro modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('best.pt')\n",
    "\n",
    "vid = cv2.VideoCapture(\"C0142.MP4\")\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if ret:\n",
    "        results = model(frame, show=False)\n",
    "        annotated_frame = results[0].plot()\n",
    "        cv2.imshow(\"Deteccion de YOLO\", annotated_frame)\n",
    "\n",
    "        # Salir del vídeo cuando presionamos ESC\n",
    "        if cv2.waitKey(1) & 0xFF == 27 or cv2.getWindowProperty(\"Deteccion de YOLO\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "    else:\n",
    "        # El vídeo ya se terminó\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b0a81a",
   "metadata": {},
   "source": [
    "### Usamos el modelo pre-entrenado de YOLO y el nuestro en conjunto \n",
    "Utilizamos el modelo pre-entrenado para detectar personas y vehículos, posteriormente, cuando hayamos detectado un vehículo, se lo pasamos a nuestro modelo entrenado en matrículas para que le detecte la matrícula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d241ad",
   "metadata": {},
   "source": [
    "Código para las detecciones de OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código necesario para el VLM\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "import torch\n",
    "device = \"cpu\"  # or \"cpu\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-Instruct\")\n",
    "model = AutoModelForImageTextToText.from_pretrained(\"HuggingFaceTB/SmolVLM-Instruct\",\n",
    "                                                dtype=torch.bfloat16,\n",
    "                                                _attn_implementation=\"flash_attention_2\" if device == \"cuda\" else \"eager\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69c034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "# Solo se está usando en el Tesseract (Se elimina?)\n",
    "def preprocess_for_ocr(img_crop, escala=4):\n",
    "\n",
    "    img = cv2.resize(img_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray_blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray_blur,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        13,\n",
    "        2\n",
    "    )\n",
    "\n",
    "    return thresh\n",
    "\n",
    "reader = easyocr.Reader(['es'], gpu=False) \n",
    "\n",
    "def ocr_easy(placa_crop, frame, x1, y1, last_plate=None):\n",
    "    escala = 3\n",
    "    placa_crop = cv2.resize(placa_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    gray = cv2.cvtColor(placa_crop, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    gray = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)\n",
    "\n",
    "    ocr_result = reader.readtext(\n",
    "        gray,\n",
    "        allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
    "        detail=1\n",
    "    )\n",
    "\n",
    "    text = \"\"\n",
    "\n",
    "    if len(ocr_result) > 0:\n",
    "        text = ocr_result[0][1].strip()\n",
    "        prob = ocr_result[0][2]\n",
    "\n",
    "        if len(text) >= 4 and prob > 0.5 and text != last_plate:\n",
    "            last_plate = text\n",
    "            timestamp = vid.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "            print(f\"[{timestamp:.2f}s] Matrícula: {text} (Conf: {prob:.2f})\")\n",
    "            cv2.putText(frame, f'{text}', (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    return text\n",
    "\n",
    "def ocr_vlm(crop, frame, x1, y1, x2, y2):\n",
    "    plate_img = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": \"Read the text on this license plate.\"}\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(text=prompt, images=[plate_img], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=10)\n",
    "        generated_texts = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        plate_text = generated_texts[0].strip()\n",
    "\n",
    "        if \"Assistant: \" in plate_text:\n",
    "            raw_text = plate_text.split(\"Assistant: \")[1]\n",
    "        else:\n",
    "            plate_text = raw_text\n",
    "\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(frame, raw_text, (x1, max(30, y1 - 10)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    return raw_text\n",
    "\n",
    "# NO SE USA (Lo eliminamos cuando esté confirmado que usamos los otros dos)\n",
    "def ocr_tesseract(placa_crop, frame_count, cap, crop_dir=\"crops/\", last_texts=set()):\n",
    "    if placa_crop.size > 0:\n",
    "        gray = preprocess_for_ocr(placa_crop)\n",
    "\n",
    "        # Usando Tesseract\n",
    "        ocr_result = pytesseract.image_to_data(\n",
    "            gray,\n",
    "            output_type=Output.DICT,\n",
    "            config='--psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
    "        )\n",
    "\n",
    "        n_boxes = len(ocr_result['text'])\n",
    "        for i in range(n_boxes):\n",
    "            text = ocr_result['text'][i].strip().replace(\" \", \"\")\n",
    "            conf = float(ocr_result['conf'][i])\n",
    "            if len(text) >= 7 and conf > 60 and text not in last_texts:\n",
    "                last_texts.add(text)\n",
    "                timestamp = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "                print(f\"[{timestamp:.2f}s] Matrícula detectada: {text} (Conf: {conf:.2f})\")\n",
    "\n",
    "                cv2.putText(frame, text, (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                crop_filename = os.path.join(crop_dir, f\"{text}_{frame_count}.jpg\")\n",
    "                cv2.imwrite(crop_filename, gray)\n",
    "                print(f\"Guardada imagen: {crop_filename}\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e835c4b",
   "metadata": {},
   "source": [
    "Código principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b49dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 11 motorcycles, 902.4ms\n",
      "Speed: 8.7ms preprocess, 902.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 215.7ms\n",
      "Speed: 82.6ms preprocess, 215.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x608 (no detections), 152.2ms\n",
      "Speed: 5.5ms preprocess, 152.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 640x544 1 matricula, 112.6ms\n",
      "Speed: 7.2ms preprocess, 112.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 576x640 (no detections), 109.3ms\n",
      "Speed: 5.8ms preprocess, 109.3ms inference, 0.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x480 (no detections), 90.2ms\n",
      "Speed: 2.1ms preprocess, 90.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 288x640 (no detections), 49.6ms\n",
      "Speed: 1.6ms preprocess, 49.6ms inference, 0.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 640x640 (no detections), 82.2ms\n",
      "Speed: 4.8ms preprocess, 82.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 83.9ms\n",
      "Speed: 4.8ms preprocess, 83.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 matricula, 91.7ms\n",
      "Speed: 5.2ms preprocess, 91.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 76.8ms\n",
      "Speed: 4.1ms preprocess, 76.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 83.4ms\n",
      "Speed: 4.9ms preprocess, 83.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 (no detections), 68.2ms\n",
      "Speed: 1.7ms preprocess, 68.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 (no detections), 111.1ms\n",
      "Speed: 3.1ms preprocess, 111.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 384x640 2 cars, 11 motorcycles, 112.0ms\n",
      "Speed: 3.5ms preprocess, 112.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.1ms\n",
      "Speed: 3.0ms preprocess, 92.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x608 (no detections), 109.0ms\n",
      "Speed: 6.0ms preprocess, 109.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 640x544 1 matricula, 81.1ms\n",
      "Speed: 4.7ms preprocess, 81.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 576x640 (no detections), 86.0ms\n",
      "Speed: 4.3ms preprocess, 86.0ms inference, 0.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x480 (no detections), 75.1ms\n",
      "Speed: 2.2ms preprocess, 75.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 288x640 (no detections), 53.7ms\n",
      "Speed: 1.8ms preprocess, 53.7ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 640x640 (no detections), 96.9ms\n",
      "Speed: 4.9ms preprocess, 96.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 90.2ms\n",
      "Speed: 5.1ms preprocess, 90.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 matricula, 97.5ms\n",
      "Speed: 5.6ms preprocess, 97.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 96.3ms\n",
      "Speed: 5.8ms preprocess, 96.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 85.2ms\n",
      "Speed: 5.3ms preprocess, 85.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 (no detections), 67.5ms\n",
      "Speed: 1.6ms preprocess, 67.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 (no detections), 74.8ms\n",
      "Speed: 2.9ms preprocess, 74.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 384x640 2 cars, 11 motorcycles, 60.1ms\n",
      "Speed: 1.7ms preprocess, 60.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 62.7ms\n",
      "Speed: 3.1ms preprocess, 62.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x608 (no detections), 87.0ms\n",
      "Speed: 5.2ms preprocess, 87.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 640x544 1 matricula, 77.7ms\n",
      "Speed: 3.8ms preprocess, 77.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 576x640 (no detections), 94.5ms\n",
      "Speed: 6.1ms preprocess, 94.5ms inference, 0.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x480 (no detections), 80.8ms\n",
      "Speed: 2.5ms preprocess, 80.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 288x640 (no detections), 58.2ms\n",
      "Speed: 1.9ms preprocess, 58.2ms inference, 0.6ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 640x640 (no detections), 85.9ms\n",
      "Speed: 4.8ms preprocess, 85.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 85.7ms\n",
      "Speed: 5.7ms preprocess, 85.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 matricula, 86.6ms\n",
      "Speed: 5.4ms preprocess, 86.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 82.4ms\n",
      "Speed: 5.1ms preprocess, 82.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 79.8ms\n",
      "Speed: 5.0ms preprocess, 79.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 (no detections), 70.8ms\n",
      "Speed: 1.9ms preprocess, 70.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 (no detections), 80.4ms\n",
      "Speed: 2.8ms preprocess, 80.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 384x640 2 cars, 11 motorcycles, 58.8ms\n",
      "Speed: 2.4ms preprocess, 58.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 62.2ms\n",
      "Speed: 2.7ms preprocess, 62.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x608 (no detections), 81.8ms\n",
      "Speed: 5.8ms preprocess, 81.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 640x544 1 matricula, 77.7ms\n",
      "Speed: 4.3ms preprocess, 77.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 576x640 (no detections), 79.7ms\n",
      "Speed: 4.3ms preprocess, 79.7ms inference, 0.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x480 (no detections), 74.9ms\n",
      "Speed: 2.4ms preprocess, 74.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 288x640 (no detections), 50.5ms\n",
      "Speed: 1.9ms preprocess, 50.5ms inference, 0.6ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 640x640 (no detections), 93.3ms\n",
      "Speed: 5.4ms preprocess, 93.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 84.4ms\n",
      "Speed: 5.7ms preprocess, 84.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 92.4ms\n",
      "Speed: 5.2ms preprocess, 92.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 91.6ms\n",
      "Speed: 4.9ms preprocess, 91.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 84.5ms\n",
      "Speed: 5.0ms preprocess, 84.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 (no detections), 72.9ms\n",
      "Speed: 1.5ms preprocess, 72.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x576 2 matriculas, 81.8ms\n",
      "Speed: 4.7ms preprocess, 81.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "0: 384x640 2 cars, 11 motorcycles, 78.7ms\n",
      "Speed: 2.4ms preprocess, 78.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.1ms\n",
      "Speed: 3.0ms preprocess, 82.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x608 (no detections), 98.9ms\n",
      "Speed: 5.9ms preprocess, 98.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 640x544 1 matricula, 92.0ms\n",
      "Speed: 5.6ms preprocess, 92.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 576x640 (no detections), 91.5ms\n",
      "Speed: 5.3ms preprocess, 91.5ms inference, 0.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x480 (no detections), 81.9ms\n",
      "Speed: 2.4ms preprocess, 81.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 288x640 (no detections), 65.4ms\n",
      "Speed: 1.7ms preprocess, 65.4ms inference, 0.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 640x640 (no detections), 95.3ms\n",
      "Speed: 6.4ms preprocess, 95.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 97.4ms\n",
      "Speed: 5.0ms preprocess, 97.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 102.3ms\n",
      "Speed: 5.8ms preprocess, 102.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 104.5ms\n",
      "Speed: 6.5ms preprocess, 104.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 102.0ms\n",
      "Speed: 5.4ms preprocess, 102.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 (no detections), 78.0ms\n",
      "Speed: 2.2ms preprocess, 78.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x608 (no detections), 101.2ms\n",
      "Speed: 5.4ms preprocess, 101.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 384x640 2 cars, 11 motorcycles, 69.8ms\n",
      "Speed: 2.7ms preprocess, 69.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 61.3ms\n",
      "Speed: 2.7ms preprocess, 61.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x608 (no detections), 82.0ms\n",
      "Speed: 3.7ms preprocess, 82.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 640x544 1 matricula, 71.9ms\n",
      "Speed: 4.0ms preprocess, 71.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 576x640 (no detections), 76.1ms\n",
      "Speed: 4.5ms preprocess, 76.1ms inference, 0.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x480 (no detections), 67.0ms\n",
      "Speed: 2.0ms preprocess, 67.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 288x640 (no detections), 50.8ms\n",
      "Speed: 2.0ms preprocess, 50.8ms inference, 0.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 640x640 (no detections), 83.1ms\n",
      "Speed: 3.5ms preprocess, 83.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 81.3ms\n",
      "Speed: 4.9ms preprocess, 81.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 87.4ms\n",
      "Speed: 5.2ms preprocess, 87.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 96.9ms\n",
      "Speed: 5.8ms preprocess, 96.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 79.5ms\n",
      "Speed: 4.1ms preprocess, 79.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 (no detections), 68.3ms\n",
      "Speed: 3.1ms preprocess, 68.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x608 (no detections), 80.1ms\n",
      "Speed: 4.7ms preprocess, 80.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 384x640 2 cars, 11 motorcycles, 58.2ms\n",
      "Speed: 2.0ms preprocess, 58.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 56.2ms\n",
      "Speed: 2.5ms preprocess, 56.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x608 (no detections), 74.2ms\n",
      "Speed: 4.2ms preprocess, 74.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 640x544 1 matricula, 66.6ms\n",
      "Speed: 3.6ms preprocess, 66.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 576x640 (no detections), 75.5ms\n",
      "Speed: 4.2ms preprocess, 75.5ms inference, 0.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x480 (no detections), 67.7ms\n",
      "Speed: 2.4ms preprocess, 67.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 288x640 (no detections), 48.7ms\n",
      "Speed: 1.9ms preprocess, 48.7ms inference, 0.6ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 640x640 (no detections), 82.3ms\n",
      "Speed: 4.5ms preprocess, 82.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 83.6ms\n",
      "Speed: 5.2ms preprocess, 83.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 96.1ms\n",
      "Speed: 5.2ms preprocess, 96.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 89.0ms\n",
      "Speed: 6.2ms preprocess, 89.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 80.0ms\n",
      "Speed: 4.2ms preprocess, 80.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 (no detections), 65.3ms\n",
      "Speed: 2.2ms preprocess, 65.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x608 (no detections), 81.4ms\n",
      "Speed: 4.5ms preprocess, 81.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 384x640 2 cars, 11 motorcycles, 58.6ms\n",
      "Speed: 2.2ms preprocess, 58.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 52.2ms\n",
      "Speed: 1.9ms preprocess, 52.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x608 (no detections), 86.6ms\n",
      "Speed: 3.4ms preprocess, 86.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 640x544 1 matricula, 70.3ms\n",
      "Speed: 4.6ms preprocess, 70.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 576x640 (no detections), 75.2ms\n",
      "Speed: 4.3ms preprocess, 75.2ms inference, 0.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x480 (no detections), 67.1ms\n",
      "Speed: 2.1ms preprocess, 67.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 288x640 (no detections), 48.7ms\n",
      "Speed: 1.5ms preprocess, 48.7ms inference, 0.6ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 640x640 (no detections), 93.4ms\n",
      "Speed: 5.2ms preprocess, 93.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 92.9ms\n",
      "Speed: 5.9ms preprocess, 92.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 82.0ms\n",
      "Speed: 5.6ms preprocess, 82.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 80.7ms\n",
      "Speed: 5.2ms preprocess, 80.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 82.0ms\n",
      "Speed: 4.6ms preprocess, 82.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 (no detections), 68.4ms\n",
      "Speed: 1.9ms preprocess, 68.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x608 (no detections), 83.1ms\n",
      "Speed: 4.7ms preprocess, 83.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 384x640 2 cars, 11 motorcycles, 57.9ms\n",
      "Speed: 1.9ms preprocess, 57.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 62.6ms\n",
      "Speed: 2.7ms preprocess, 62.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x608 (no detections), 84.8ms\n",
      "Speed: 5.1ms preprocess, 84.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 640x544 1 matricula, 120.9ms\n",
      "Speed: 5.2ms preprocess, 120.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 576x640 (no detections), 118.3ms\n",
      "Speed: 8.3ms preprocess, 118.3ms inference, 0.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x480 (no detections), 88.1ms\n",
      "Speed: 2.5ms preprocess, 88.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 288x640 (no detections), 61.8ms\n",
      "Speed: 1.7ms preprocess, 61.8ms inference, 0.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 640x640 (no detections), 105.5ms\n",
      "Speed: 5.5ms preprocess, 105.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 77.1ms\n",
      "Speed: 4.1ms preprocess, 77.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 80.6ms\n",
      "Speed: 4.0ms preprocess, 80.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 84.0ms\n",
      "Speed: 5.3ms preprocess, 84.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 81.5ms\n",
      "Speed: 5.0ms preprocess, 81.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 (no detections), 70.2ms\n",
      "Speed: 2.5ms preprocess, 70.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x608 (no detections), 85.9ms\n",
      "Speed: 4.9ms preprocess, 85.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 608)\n",
      "[['frame', 'car', tensor([0.7202]), '1', 207, 268, 513, 442, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.6422]), '2', 0, 398, 211, 628, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4299]), '3', 166, 375, 327, 576, 'plate', tensor([0.2980]), 0, 168, 9, 201, ''], ['frame', 'motorcycle', tensor([0.4253]), '4', 313, 364, 491, 521, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4231]), '5', 246, 379, 375, 551, 'plate', '', '', '', '', '', ''], ['frame', 'car', tensor([0.3925]), '6', 784, 245, 1149, 397, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3846]), '7', 281, 375, 436, 536, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3609]), '8', 26, 380, 245, 591, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3458]), '9', 137, 355, 354, 572, 'plate', tensor([0.3728]), 0, 163, 18, 174, ''], ['frame', 'motorcycle', tensor([0.3427]), '10', 68, 325, 328, 577, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3253]), '11', 172, 354, 376, 554, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.2562]), '12', 391, 374, 493, 510, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.2559]), '13', 85, 389, 243, 588, 'plate', '', '', '', '', '', ''], ['frame', 'car', tensor([0.7201]), '1', 207, 268, 513, 442, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.6417]), '2', 0, 398, 211, 628, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4298]), '3', 166, 375, 327, 576, 'plate', tensor([0.2980]), 0, 168, 9, 201, ''], ['frame', 'motorcycle', tensor([0.4255]), '4', 313, 364, 491, 521, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4230]), '5', 246, 379, 375, 551, 'plate', '', '', '', '', '', ''], ['frame', 'car', tensor([0.3916]), '6', 784, 245, 1149, 397, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3846]), '7', 281, 375, 436, 536, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3605]), '8', 26, 380, 245, 591, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3456]), '9', 137, 355, 354, 572, 'plate', tensor([0.3728]), 0, 163, 18, 174, ''], ['frame', 'motorcycle', tensor([0.3431]), '10', 68, 325, 328, 577, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3248]), '11', 172, 354, 376, 554, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.2559]), '12', 391, 374, 493, 510, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.2559]), '13', 85, 389, 243, 588, 'plate', '', '', '', '', '', ''], ['frame', 'car', tensor([0.7204]), '1', 207, 268, 513, 442, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.6424]), '2', 0, 398, 211, 628, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4299]), '3', 166, 375, 327, 576, 'plate', tensor([0.2980]), 0, 168, 9, 201, ''], ['frame', 'motorcycle', tensor([0.4253]), '4', 313, 364, 491, 521, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4231]), '5', 246, 379, 375, 551, 'plate', '', '', '', '', '', ''], ['frame', 'car', tensor([0.3925]), '6', 784, 245, 1149, 397, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3846]), '7', 281, 375, 436, 536, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3610]), '8', 26, 380, 245, 591, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3457]), '9', 137, 355, 354, 572, 'plate', tensor([0.3728]), 0, 163, 18, 174, ''], ['frame', 'motorcycle', tensor([0.3427]), '10', 68, 325, 328, 577, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3253]), '11', 172, 354, 376, 554, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.2563]), '12', 391, 374, 493, 510, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.2559]), '13', 85, 389, 243, 588, 'plate', '', '', '', '', '', ''], ['frame', 'car', tensor([0.7153]), '1', 207, 268, 513, 442, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.6380]), '2', 0, 398, 211, 628, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4310]), '3', 166, 375, 327, 576, 'plate', tensor([0.2980]), 0, 168, 9, 201, ''], ['frame', 'motorcycle', tensor([0.4256]), '4', 313, 365, 491, 522, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4230]), '5', 246, 379, 375, 551, 'plate', '', '', '', '', '', ''], ['frame', 'car', tensor([0.3892]), '6', 784, 245, 1149, 398, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3835]), '7', 281, 375, 436, 536, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3201]), '8', 14, 371, 245, 595, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3448]), '9', 137, 355, 354, 573, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3411]), '10', 68, 325, 328, 577, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3239]), '11', 172, 354, 376, 554, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.2523]), '12', 391, 374, 493, 510, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3543]), '13', 69, 383, 246, 582, 'plate', tensor([0.7800, 0.3758]), 0, 95, 9, 116, ''], ['frame', 'car', tensor([0.7152]), '1', 207, 268, 513, 442, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.6378]), '2', 0, 398, 211, 628, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4309]), '3', 166, 375, 327, 576, 'plate', tensor([0.2980]), 0, 168, 9, 201, ''], ['frame', 'motorcycle', tensor([0.4255]), '4', 313, 365, 491, 522, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4229]), '5', 246, 379, 375, 551, 'plate', '', '', '', '', '', ''], ['frame', 'car', tensor([0.3891]), '6', 784, 245, 1149, 398, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3835]), '7', 281, 375, 436, 536, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3201]), '8', 10, 369, 245, 597, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3448]), '9', 137, 355, 354, 573, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3411]), '10', 68, 325, 328, 577, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3239]), '11', 172, 355, 376, 554, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.2524]), '12', 391, 374, 493, 510, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3543]), '13', 64, 381, 247, 580, 'plate', '', '', '', '', '', ''], ['frame', 'car', tensor([0.7226]), '1', 207, 268, 513, 441, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.6378]), '2', 0, 397, 211, 628, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4317]), '3', 166, 375, 327, 576, 'plate', tensor([0.2980]), 0, 168, 9, 201, ''], ['frame', 'motorcycle', tensor([0.4239]), '4', 313, 365, 491, 522, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4229]), '5', 246, 379, 375, 551, 'plate', '', '', '', '', '', ''], ['frame', 'car', tensor([0.4340]), '6', 785, 245, 1148, 396, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3818]), '7', 281, 375, 436, 536, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3182]), '8', 9, 368, 245, 597, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3443]), '9', 137, 355, 354, 573, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3400]), '10', 69, 325, 328, 577, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3245]), '11', 172, 354, 376, 554, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.2468]), '12', 391, 374, 493, 510, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3530]), '13', 63, 381, 247, 580, 'plate', '', '', '', '', '', ''], ['frame', 'car', tensor([0.7230]), '1', 207, 268, 513, 441, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.6381]), '2', 0, 397, 211, 628, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4316]), '3', 166, 375, 327, 576, 'plate', tensor([0.2980]), 0, 168, 9, 201, ''], ['frame', 'motorcycle', tensor([0.4241]), '4', 313, 365, 491, 522, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4226]), '5', 246, 379, 375, 551, 'plate', '', '', '', '', '', ''], ['frame', 'car', tensor([0.4440]), '6', 785, 245, 1148, 396, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3818]), '7', 281, 375, 436, 536, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3187]), '8', 9, 368, 245, 597, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3445]), '9', 137, 355, 354, 573, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3409]), '10', 69, 325, 328, 577, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3242]), '11', 172, 354, 376, 554, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.2463]), '12', 391, 374, 493, 510, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3531]), '13', 63, 381, 247, 580, 'plate', '', '', '', '', '', ''], ['frame', 'car', tensor([0.7247]), '1', 207, 268, 513, 441, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.6377]), '2', 0, 397, 211, 628, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4313]), '3', 166, 375, 327, 576, 'plate', tensor([0.2980]), 0, 168, 9, 201, ''], ['frame', 'motorcycle', tensor([0.4238]), '4', 313, 365, 491, 522, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4230]), '5', 246, 379, 375, 551, 'plate', '', '', '', '', '', ''], ['frame', 'car', tensor([0.4421]), '6', 785, 245, 1148, 395, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3815]), '7', 281, 375, 436, 536, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3189]), '8', 9, 368, 245, 597, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3445]), '9', 137, 355, 354, 573, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3400]), '10', 69, 325, 328, 577, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3249]), '11', 172, 354, 376, 554, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.2481]), '12', 391, 374, 493, 510, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3535]), '13', 63, 381, 247, 580, 'plate', '', '', '', '', '', ''], ['frame', 'car', tensor([0.7226]), '1', 207, 268, 513, 442, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.6408]), '2', 0, 398, 211, 628, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4305]), '3', 166, 375, 327, 576, 'plate', tensor([0.2980]), 0, 168, 9, 201, ''], ['frame', 'motorcycle', tensor([0.4242]), '4', 313, 364, 491, 522, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.4241]), '5', 246, 379, 375, 551, 'plate', '', '', '', '', '', ''], ['frame', 'car', tensor([0.4627]), '6', 783, 245, 1148, 396, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3801]), '7', 281, 375, 436, 536, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3546]), '8', 20, 375, 246, 594, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3448]), '9', 137, 354, 354, 573, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3398]), '10', 69, 325, 328, 576, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.3265]), '11', 172, 354, 376, 554, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.2444]), '12', 391, 374, 493, 510, 'plate', '', '', '', '', '', ''], ['frame', 'motorcycle', tensor([0.1127]), '13', 20, 354, 233, 586, 'plate', '', '', '', '', '', '']]\n",
      "{'person': 0, 'car': 2, 'motorcycle': 11, 'bus': 0, 'truck': 0}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "BASE_MODEL_PATH = 'yolo11n.pt'\n",
    "OUR_MODEL_PATH = 'best.pt'\n",
    "\n",
    "VIDEO_PATH = \"prueba_coches.mp4\"\n",
    "base_model = YOLO(BASE_MODEL_PATH)\n",
    "our_model = YOLO(OUR_MODEL_PATH)\n",
    "vid = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "frame_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "output_path = 'resultados.mp4'\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "def data_to_csv(registros):\n",
    "    columnas = [\n",
    "        \"fotograma\", \"tipo_objeto\", \"confianza\", \"id_tracking\",\n",
    "        \"x1\", \"y1\", \"x2\", \"y2\",\n",
    "        \"matricula_detectada\", \"conf_ocr\",\n",
    "        \"mx1\", \"my1\", \"mx2\", \"my2\",\n",
    "        \"texto_matricula\"\n",
    "    ]\n",
    "\n",
    "    with open(\"resultados.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter=';')\n",
    "        writer.writerow(columnas)    \n",
    "        writer.writerows(registros)  \n",
    "\n",
    "    print(\"Archivo 'resultados.csv' creado correctamente.\")\n",
    "\n",
    "\n",
    "classes = [0, 2, 3, 5, 7]    # Person, car, motorcycle, bus, truck\n",
    "\n",
    "car_boxes = []\n",
    "car_boxes_left_coords = []\n",
    "\n",
    "track_ids = set()\n",
    "count_classes = {\"person\": 0, \"car\": 0, \"motorcycle\": 0, \"bus\": 0, \"truck\": 0}\n",
    "\n",
    "save_csv = []\n",
    "frame_count = 0\n",
    "\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    frame_count += 1\n",
    "\n",
    "    if ret:\n",
    "        base_results = base_model.track(frame, persist=True, show=False, classes=classes)\n",
    "        plates_result = None\n",
    "        annotated_frame = base_results[0].plot()\n",
    "        boxes = list()\n",
    "\n",
    "        # Mostramos un recuadro arriba a la izquierda que muestre las matrículas que se vayan detectando\n",
    "        text_box_w = int(frame.shape[1]*0.2)\n",
    "        text_box_h = int(frame.shape[0]*0.09)\n",
    "        \n",
    "        cv2.rectangle(annotated_frame, (0, 0), (text_box_w, text_box_h), (0, 0, 0), -1)\n",
    "\n",
    "        last_plate = \"\"\n",
    "        show_plate_text = \"\"\n",
    "        \n",
    "        for result in base_results:\n",
    "            boxes += result.boxes\n",
    "        for box in boxes:\n",
    "            bounding_box = box.xyxy.tolist()\n",
    "            name = result[0].names[box.cls.int().item()]\n",
    "            conf = box.conf\n",
    "            track_id = str(int(box.id[0].tolist()))\n",
    "            if track_id not in track_ids:\n",
    "                track_ids.add(track_id)\n",
    "                count_classes[name] += 1\n",
    "            x1, y1, x2, y2 = [int(item) for item in bounding_box[0]]\n",
    "            plate, plate_conf, px1, py1, px2, py2, plate_text = \"\", \"\", \"\", \"\", \"\", \"\", \"\"\n",
    "            if name != \"person\":\n",
    "                vehicle_box = frame[y1:y2, x1:x2]\n",
    "                plates_result = our_model(vehicle_box, show=False)\n",
    "                if len(plates_result[0].boxes) > 0:\n",
    "                    plate_conf = plates_result[0].boxes.conf\n",
    "                    plate_detection = (plates_result[0].boxes.xyxy).tolist()\n",
    "                    px1, py1, px2, py2 = [int(item) for item in plate_detection[0]]\n",
    "                    plate = vehicle_box[py1:py2, px1:px2]\n",
    "                    real_x1 = px1+x1\n",
    "                    real_y1 = py1+y1\n",
    "                    real_x2 = px2+x1\n",
    "                    real_y2 = py2+y1\n",
    "                    cv2.rectangle(annotated_frame, (real_x1, real_y1), (real_x2, real_y2), (0, 255, 0), 2)\n",
    "                    plate_text = ocr_easy(plate, frame, real_x1, real_y1)\n",
    "                    plate_pattern = re.compile(\"^[0-9]{4}[BCDFGHJKLMNPRSTVWXYZ]{3}$\")\n",
    "                    if plate_pattern.match(plate_text.strip()):\n",
    "                        show_plate_text = plate_text\n",
    "            if show_plate_text != last_plate:\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                (text_width, text_height), baseline = cv2.getTextSize(plate_text, font, 0.8, 2)\n",
    "                text_x = (text_box_w - text_width) // 2\n",
    "                text_y = (text_box_h + text_height) // 2 - baseline\n",
    "                cv2.putText(annotated_frame, plate_text, (text_x, text_y), font, 0.8, (255, 255, 255), 2)\n",
    "                last_plate = show_plate_text               \n",
    "            save_csv.append([\"frame\", name, conf, track_id, x1, y1, x2, y2, \"plate\", plate_conf, px1, py1, px2, py2, plate_text])\n",
    "        \n",
    "        out.write(annotated_frame)\n",
    "        \"\"\"cv2.imshow(\"Deteccion de YOLO\", annotated_frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == 27 or cv2.getWindowProperty(\"Deteccion de YOLO\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\"\"\"\n",
    "    else:\n",
    "        # El vídeo ya se terminó\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# fotograma, tipo_objeto, confianza, identificador_tracking, x1, y1, x2, y2, matrícula_en_su_caso, confianza, mx1,my1,mx2,my2, texto_matricula\n",
    "print(save_csv)\n",
    "print(count_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ca6f4",
   "metadata": {},
   "source": [
    "### Pruebas OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b308e6",
   "metadata": {},
   "source": [
    "#### Easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb0b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "from IPython.display import Video, display\n",
    "import os\n",
    "\n",
    "\n",
    "model_path = \"best.pt\"\n",
    "video_path = \"C0142.MP4\"\n",
    "crop_dir   = \"crops/\"  \n",
    "os.makedirs(crop_dir, exist_ok=True)\n",
    "\n",
    "model = YOLO(model_path)\n",
    "reader = easyocr.Reader(['en'], gpu=True)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise Exception(f\"No se pudo abrir el vídeo: {video_path}\")\n",
    "\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps_in = cap.get(cv2.CAP_PROP_FPS) or 20.0\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('resultado.mp4', fourcc, fps_in, (width, height))\n",
    "\n",
    "margin = 10\n",
    "frame_count = 0\n",
    "last_texts = set()\n",
    "\n",
    "def preprocess_for_ocr(img_crop, escala=4):\n",
    "\n",
    "    img = cv2.resize(img_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray_blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray_blur,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        13,\n",
    "        2\n",
    "    )\n",
    "\n",
    "    return thresh\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "\n",
    "    results = model(frame, verbose=False)\n",
    "    detections = results[0].boxes\n",
    "\n",
    "    for box in detections:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        conf = float(box.conf[0])\n",
    "        if conf < 0.2:\n",
    "            continue\n",
    "\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        extra = int(max(w, h) * 0.15)\n",
    "        x1m = max(0, x1 - margin - extra)\n",
    "        y1m = max(0, y1 - margin - extra)\n",
    "        x2m = min(frame.shape[1], x2 + margin + extra)\n",
    "        y2m = min(frame.shape[0], y2 + margin + extra)\n",
    "\n",
    "        placa_crop = frame[y1m:y2m, x1m:x2m]\n",
    "\n",
    "        if placa_crop.size > 0:\n",
    "\n",
    "            gray = preprocess_for_ocr(placa_crop)\n",
    "\n",
    "            ocr_result = reader.readtext(\n",
    "                gray,\n",
    "                allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
    "                detail=1,\n",
    "                text_threshold=0.2\n",
    "            )\n",
    "\n",
    "            if len(ocr_result) > 0:\n",
    "                for (bbox, text, prob) in ocr_result:\n",
    "                    text_clean = text.strip().replace(\" \", \"\")\n",
    "                    if prob > 0.7 and len(text_clean) >= 7 and text_clean not in last_texts:\n",
    "                        last_texts.add(text_clean)\n",
    "                        timestamp = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "\n",
    "                        print(f\"[{timestamp:.2f}s] Matrícula detectada: {text_clean} (Conf: {prob:.2f})\")\n",
    "\n",
    "                        cv2.putText(frame, text_clean, (x1, y1 - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                        crop_filename = os.path.join(crop_dir, f\"{text_clean}_{frame_count}.jpg\")\n",
    "                        cv2.imwrite(crop_filename, gray)\n",
    "                        print(f\"Guardada imagen: {crop_filename}\")\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Procesamiento completado. Total frames: {frame_count}\")\n",
    "display(Video('resultado.mp4', embed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c874d4",
   "metadata": {},
   "source": [
    "#### Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "from IPython.display import Video, display\n",
    "import os\n",
    "\n",
    "# Configura la ruta si Tesseract no está en PATH\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "model_path = \"best.pt\"\n",
    "video_path = \"C0142.MP4\"\n",
    "crop_dir   = \"crops/\"  \n",
    "os.makedirs(crop_dir, exist_ok=True)\n",
    "\n",
    "model = YOLO(model_path)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise Exception(f\"No se pudo abrir el vídeo: {video_path}\")\n",
    "\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps_in = cap.get(cv2.CAP_PROP_FPS) or 20.0\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('resultado_tesseract.mp4', fourcc, fps_in, (width, height))\n",
    "\n",
    "margin = 10\n",
    "frame_count = 0\n",
    "last_texts = set()\n",
    "\n",
    "def preprocess_for_ocr(img_crop, escala=4):\n",
    "    # Escala y convierte a gris\n",
    "    img = cv2.resize(img_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    # Umbral adaptativo\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray_blur,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        13,\n",
    "        2\n",
    "    )\n",
    "    return thresh\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "\n",
    "    results = model(frame, verbose=False)\n",
    "    detections = results[0].boxes\n",
    "\n",
    "    for box in detections:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        conf = float(box.conf[0])\n",
    "        if conf < 0.2:\n",
    "            continue\n",
    "\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        extra = int(max(w, h) * 0.15)\n",
    "        x1m = max(0, x1 - margin - extra)\n",
    "        y1m = max(0, y1 - margin - extra)\n",
    "        x2m = min(frame.shape[1], x2 + margin + extra)\n",
    "        y2m = min(frame.shape[0], y2 + margin + extra)\n",
    "\n",
    "        placa_crop = frame[y1m:y2m, x1m:x2m]\n",
    "\n",
    "        if placa_crop.size > 0:\n",
    "            gray = preprocess_for_ocr(placa_crop)\n",
    "\n",
    "            # Usando Tesseract\n",
    "            ocr_result = pytesseract.image_to_data(\n",
    "                gray,\n",
    "                output_type=Output.DICT,\n",
    "                config='--psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
    "            )\n",
    "\n",
    "            n_boxes = len(ocr_result['text'])\n",
    "            for i in range(n_boxes):\n",
    "                text = ocr_result['text'][i].strip().replace(\" \", \"\")\n",
    "                conf = float(ocr_result['conf'][i])\n",
    "                if len(text) >= 7 and conf > 60 and text not in last_texts:\n",
    "                    last_texts.add(text)\n",
    "                    timestamp = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "                    print(f\"[{timestamp:.2f}s] Matrícula detectada: {text} (Conf: {conf:.2f})\")\n",
    "\n",
    "                    cv2.putText(frame, text, (x1, y1 - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                    crop_filename = os.path.join(crop_dir, f\"{text}_{frame_count}.jpg\")\n",
    "                    cv2.imwrite(crop_filename, gray)\n",
    "                    print(f\"Guardada imagen: {crop_filename}\")\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Procesamiento completado. Total frames: {frame_count}\")\n",
    "display(Video('resultado_tesseract.mp4', embed=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11dceb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'resultados.csv' creado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "registros = [\n",
    "    [1, \"auto\", 0.92, 3, 120, 200, 360, 480, True, 0.88, 135, 215, 345, 465, \"ABC1234\"],\n",
    "    [1, \"moto\", 0.85, 5, 400, 220, 500, 380, False, 0.00, 0, 0, 0, 0, \"\"],\n",
    "    [2, \"auto\", 0.95, 3, 125, 205, 365, 485, True, 0.90, 140, 220, 350, 470, \"ABC1234\"],\n",
    "    [2, \"camioneta\", 0.88, 7, 600, 250, 900, 550, True, 0.75, 620, 270, 880, 530, \"XYZ9876\"],\n",
    "    [3, \"auto\", 0.93, 3, 130, 210, 370, 490, True, 0.85, 145, 225, 355, 475, \"ABC1234\"],\n",
    "    [3, \"moto\", 0.80, 5, 405, 225, 505, 385, False, 0.00, 0, 0, 0, 0, \"\"]\n",
    "]\n",
    "def data_to_csv(registros):\n",
    "    columnas = [\n",
    "        \"fotograma\", \"tipo_objeto\", \"confianza\", \"id_tracking\",\n",
    "        \"x1\", \"y1\", \"x2\", \"y2\",\n",
    "        \"matricula_detectada\", \"conf_ocr\",\n",
    "        \"mx1\", \"my1\", \"mx2\", \"my2\",\n",
    "        \"texto_matricula\"\n",
    "    ]\n",
    "\n",
    "    with open(\"resultados.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter=';')\n",
    "        writer.writerow(columnas)    \n",
    "        writer.writerows(registros)  \n",
    "\n",
    "    print(\"Archivo 'resultados.csv' creado correctamente.\")\n",
    "\n",
    "data_to_csv(registros)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
