{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64dbf540",
   "metadata": {},
   "source": [
    "Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc881425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import math \n",
    "\n",
    "from ultralytics import YOLO\n",
    "from matplotlib import pyplot as plt\n",
    "import easyocr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728c5aa",
   "metadata": {},
   "source": [
    "Extraemos las clases del modelo YOLO 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23885f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "vid = cv2.VideoCapture(\"C0142.MP4\")\n",
    "\n",
    "names = None\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if ret:\n",
    "        results = model(frame, show=False)\n",
    "        if names is None:\n",
    "            names = results[0].names\n",
    "        annotated_frame = results[0].plot()\n",
    "        cv2.imshow(\"Deteccion de YOLO\", annotated_frame)\n",
    "\n",
    "        # Salir del vídeo cuando presionamos ESC\n",
    "        if cv2.waitKey(1) & 0xFF == 27 or cv2.getWindowProperty(\"Deteccion de YOLO\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "    else:\n",
    "        # El vídeo ya se terminó\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Leemos las posibles clases\n",
    "with open(\"classes.txt\", \"w\") as f:\n",
    "    f.write(str(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d49077",
   "metadata": {},
   "source": [
    "### Mostramos el funcionamiento de nuestro modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('best.pt')\n",
    "\n",
    "vid = cv2.VideoCapture(\"C0142.MP4\")\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if ret:\n",
    "        results = model(frame, show=False)\n",
    "        annotated_frame = results[0].plot()\n",
    "        cv2.imshow(\"Deteccion de YOLO\", annotated_frame)\n",
    "\n",
    "        # Salir del vídeo cuando presionamos ESC\n",
    "        if cv2.waitKey(1) & 0xFF == 27 or cv2.getWindowProperty(\"Deteccion de YOLO\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "    else:\n",
    "        # El vídeo ya se terminó\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "971154ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31.28s] Matrícula: 271LC (Conf: 0.55)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO('best.pt')\n",
    "reader = easyocr.Reader(['es'])\n",
    "vid = cv2.VideoCapture(\"C0142.MP4\")\n",
    "\n",
    "if not vid.isOpened():\n",
    "    exit()\n",
    "\n",
    "frame_count = 0\n",
    "frame_skip = 3\n",
    "last_plate = None\n",
    "margin = 10  \n",
    "\n",
    "while True:\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    results = model(frame, verbose=False)\n",
    "    detections = results[0].boxes\n",
    "\n",
    "    for box in detections:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "        if frame_count % frame_skip == 0:\n",
    "            x1m = max(0, x1 - margin)\n",
    "            y1m = max(0, y1 - margin)\n",
    "            x2m = min(frame.shape[1], x2 + margin)\n",
    "            y2m = min(frame.shape[0], y2 + margin)\n",
    "            placa_crop = frame[y1m:y2m, x1m:x2m]\n",
    "\n",
    "            if placa_crop.size > 0:\n",
    "                escala = 3\n",
    "                placa_crop = cv2.resize(placa_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "                gray = cv2.cvtColor(placa_crop, cv2.COLOR_BGR2GRAY)\n",
    "                gray = cv2.equalizeHist(gray)\n",
    "                gray = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)\n",
    "\n",
    "                ocr_result = reader.readtext(\n",
    "                    gray,\n",
    "                    allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
    "                    detail=1\n",
    "                )\n",
    "\n",
    "                if len(ocr_result) > 0:\n",
    "                    text = ocr_result[0][1].strip()\n",
    "                    prob = ocr_result[0][2]\n",
    "\n",
    "                    if len(text) >= 4 and prob > 0.5 and text != last_plate:\n",
    "                        last_plate = text\n",
    "                        timestamp = vid.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "                        print(f\"[{timestamp:.2f}s] Matrícula: {text} (Conf: {prob:.2f})\")\n",
    "                        cv2.putText(frame, f'{text}', (x1, y1 - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"Detección + OCR\", frame)\n",
    "    if cv2.waitKey(30) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b0a81a",
   "metadata": {},
   "source": [
    "### Usamos el modelo pre-entrenado de YOLO y el nuestro en conjunto \n",
    "Utilizamos el modelo pre-entrenado para detectar personas y vehículos, posteriormente, cuando hayamos detectado un vehículo, se lo pasamos a nuestro modelo entrenado en matrículas para que le detecte la matrícula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = YOLO('yolo11n.pt')\n",
    "our_model = YOLO('best.pt')\n",
    "vid = cv2.VideoCapture(\"prueba_coches.mp4\")\n",
    "\n",
    "frame_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "output_path = 'resultados.mp4'\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "def ocr(placa_crop, last_plate=None):\n",
    "    escala = 3\n",
    "    placa_crop = cv2.resize(placa_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    gray = cv2.cvtColor(placa_crop, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    gray = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)\n",
    "\n",
    "    ocr_result = reader.readtext(\n",
    "        gray,\n",
    "        allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
    "        detail=1\n",
    "    )\n",
    "\n",
    "    text = \"\"\n",
    "\n",
    "    if len(ocr_result) > 0:\n",
    "        text = ocr_result[0][1].strip()\n",
    "        prob = ocr_result[0][2]\n",
    "\n",
    "        if len(text) >= 4 and prob > 0.5 and text != last_plate:\n",
    "            last_plate = text\n",
    "            timestamp = vid.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "            print(f\"[{timestamp:.2f}s] Matrícula: {text} (Conf: {prob:.2f})\")\n",
    "            cv2.putText(frame, f'{text}', (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    return text\n",
    "\n",
    "reader = easyocr.Reader(['es'], gpu=False) \n",
    "\n",
    "classes = [0, 2, 3, 5, 7]    # Person, car, motorcycle, bus, truck\n",
    "\n",
    "car_boxes = []\n",
    "car_boxes_left_coords = []\n",
    "\n",
    "save_csv = []\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if ret:\n",
    "        base_results = base_model.track(frame, persist=True, show=False, classes=classes)\n",
    "        plates_result = None\n",
    "        annotated_frame = base_results[0].plot()\n",
    "        boxes = list()\n",
    "        for result in base_results:\n",
    "            boxes += result.boxes\n",
    "        for box in boxes:\n",
    "            bounding_box = box.xyxy.tolist()\n",
    "            name = result[0].names[box.cls.int().item()]\n",
    "            conf = box.conf\n",
    "            track_id = str(int(box.id[0].tolist()))\n",
    "            x1, y1, x2, y2 = [int(item) for item in bounding_box[0]]\n",
    "            plate, plate_conf, px1, py1, px2, py2, plate_text = \"\", \"\", \"\", \"\", \"\", \"\", \"\"\n",
    "            if name != \"person\":\n",
    "                vehicle_box = frame[y1:y2, x1:x2]\n",
    "                plates_result = our_model(vehicle_box, show=False)\n",
    "                if len(plates_result[0].boxes) > 0:\n",
    "                    plate_conf = plates_result[0].boxes.conf\n",
    "                    plate_detection = (plates_result[0].boxes.xyxy).tolist()\n",
    "                    px1, py1, px2, py2 = [int(item) for item in plate_detection[0]]\n",
    "                    plate = vehicle_box[py1:py2, px1:px2]\n",
    "                    real_x1 = px1+x1\n",
    "                    real_y1 = py1+y1\n",
    "                    real_x2 = px2+x1\n",
    "                    real_y2 = py2+y1\n",
    "                    plate_text = ocr(plate)\n",
    "                    cv2.rectangle(annotated_frame, (real_x1, real_y1), (real_x2, real_y2), (0, 255, 0), 1)\n",
    "            save_csv.append([frame, name, conf, track_id, x1, y1, x2, y2, plate, plate_conf, px1, py1, px2, py2, plate_text])\n",
    "                        \n",
    "        out.write(annotated_frame)\n",
    "    else:\n",
    "        # El vídeo ya se terminó\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# fotograma, tipo_objeto, confianza, identificador_tracking, x1, y1, x2, y2, matrícula_en_su_caso, confianza, mx1,my1,mx2,my2, texto_matricula\n",
    "print(save_csv)\n",
    "\n",
    "# Mostrar el total de cada clase\n",
    "count_classes = {\"person\": 0, \"car\": 0, \"motorcycle\": 0, \"bus\": 0, \"truck\": 0}\n",
    "for row in save_csv:\n",
    "    for c in count_classes.keys(): \n",
    "        if c in row[1]:\n",
    "            count_classes[c] += 1\n",
    "print(count_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5393f7c2",
   "metadata": {},
   "source": [
    "Opción 2 (por si hace falta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76680639",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_results = base_model(frame, show=False, classes=classes)\n",
    "plates_result = None\n",
    "annotated_frame = base_results[0].plot()\n",
    "for box in result.boxes:\n",
    "    if result.names[int(box.cls)] != \"person\":\n",
    "        x1, y1, x2, y2 = box.xyxy[0].int().tolist()\n",
    "        car_boxes.append(frame[y1:y2, x1:x2])\n",
    "        car_boxes_left_coords.append((x1, y1))\n",
    "if car_boxes:\n",
    "    plates_results = our_model(car_boxes, show=False)\n",
    "    for i, plates_result in enumerate(plates_results):\n",
    "        car_x, car_y = car_boxes_left_coords[i]\n",
    "        if len(plates_result.boxes) > 0:\n",
    "            px1, py1, px2, py2 = plates_result.boxes[0].xyxy[0].int().tolist()\n",
    "            real_x1 = px1 + car_x\n",
    "            real_y1 = py1 + car_y\n",
    "            real_x2 = px2 + car_x\n",
    "            real_y2 = py2 + car_y\n",
    "            cv2.rectangle(annotated_frame, (real_x1, real_y1), (real_x2, real_y2), (0, 255, 0), 3)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ca6f4",
   "metadata": {},
   "source": [
    "Pruebas OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb0b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "from IPython.display import Video, display\n",
    "import os\n",
    "\n",
    "\n",
    "model_path = \"best.pt\"\n",
    "video_path = \"C0142.MP4\"\n",
    "crop_dir   = \"crops/\"  \n",
    "os.makedirs(crop_dir, exist_ok=True)\n",
    "\n",
    "model = YOLO(model_path)\n",
    "reader = easyocr.Reader(['en'], gpu=True)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise Exception(f\"No se pudo abrir el vídeo: {video_path}\")\n",
    "\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps_in = cap.get(cv2.CAP_PROP_FPS) or 20.0\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('resultado.mp4', fourcc, fps_in, (width, height))\n",
    "\n",
    "margin = 10\n",
    "frame_count = 0\n",
    "last_texts = set()\n",
    "\n",
    "def preprocess_for_ocr(img_crop, escala=4):\n",
    "\n",
    "    img = cv2.resize(img_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray_blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray_blur,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        13,\n",
    "        2\n",
    "    )\n",
    "\n",
    "    return thresh\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "\n",
    "    results = model(frame, verbose=False)\n",
    "    detections = results[0].boxes\n",
    "\n",
    "    for box in detections:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        conf = float(box.conf[0])\n",
    "        if conf < 0.6:\n",
    "            continue\n",
    "\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        extra = int(max(w, h) * 0.15)\n",
    "        x1m = max(0, x1 - margin - extra)\n",
    "        y1m = max(0, y1 - margin - extra)\n",
    "        x2m = min(frame.shape[1], x2 + margin + extra)\n",
    "        y2m = min(frame.shape[0], y2 + margin + extra)\n",
    "\n",
    "        placa_crop = frame[y1m:y2m, x1m:x2m]\n",
    "\n",
    "        if placa_crop.size > 0:\n",
    "\n",
    "            gray = preprocess_for_ocr(placa_crop)\n",
    "\n",
    "            ocr_result = reader.readtext(\n",
    "                gray,\n",
    "                allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
    "                detail=1,\n",
    "                text_threshold=0.4\n",
    "            )\n",
    "\n",
    "            if len(ocr_result) > 0:\n",
    "                for (bbox, text, prob) in ocr_result:\n",
    "                    text_clean = text.strip().replace(\" \", \"\")\n",
    "                    if prob > 0.7 and len(text_clean) >= 7 and text_clean not in last_texts:\n",
    "                        last_texts.add(text_clean)\n",
    "                        timestamp = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "\n",
    "                        print(f\"[{timestamp:.2f}s] Matrícula detectada: {text_clean} (Conf: {prob:.2f})\")\n",
    "\n",
    "                        cv2.putText(frame, text_clean, (x1, y1 - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                        crop_filename = os.path.join(crop_dir, f\"{text_clean}_{frame_count}.jpg\")\n",
    "                        cv2.imwrite(crop_filename, gray)\n",
    "                        print(f\"Guardada imagen: {crop_filename}\")\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Procesamiento completado. Total frames: {frame_count}\")\n",
    "display(Video('resultado.mp4', embed=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4_easyOCR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
