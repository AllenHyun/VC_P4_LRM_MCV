{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ead8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import Video, display\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from ultralytics import YOLO\n",
    "\n",
    "PATH = \"/kaggle/input/matriculas-comparativa\"\n",
    "OUR_MODEL_PATH = '/kaggle/input/best-pt/pytorch/yolo11n/1/best.pt'\n",
    "\n",
    "our_model = YOLO(OUR_MODEL_PATH)\n",
    "our_model.to('cuda')\n",
    "\n",
    "correct_vlm = 0\n",
    "correct_easy = 0\n",
    "time_vlm = 0.0\n",
    "time_easy = 0.0\n",
    "\n",
    "image_files = [\n",
    "    f for f in os.listdir(PATH)\n",
    "    if f.lower().endswith((\".jpg\", \".jpeg\"))\n",
    "]\n",
    "\n",
    "\n",
    "for img_name in tqdm(image_files, desc=\"Procesamiento de matrículas\"):\n",
    "    img_path = os.path.join(PATH, img_name)\n",
    "    label = os.path.splitext(img_name)[0].upper()\n",
    "\n",
    "    frame = cv2.imread(img_path)\n",
    "    if frame is None:\n",
    "        continue\n",
    "\n",
    "    result = our_model(frame, show=False)\n",
    "    plate = result[0].boxes.xyxy.tolist()\n",
    "    x1, y1, x2, y2 = [int(item) for item in plate[0]]\n",
    "\n",
    "    start = time.time()\n",
    "    try:\n",
    "        text_vlm = ocr_vlm_com(frame, x1, y1, x2, y2, processor, model, device=\"cuda\", max_new_tokens=15)\n",
    "    except Exception as e:\n",
    "        print(f\"[VLM error on {img_name}]: {e}\")\n",
    "        text_vlm = \"\"\n",
    "    time_vlm += time.time() - start\n",
    "    if text_vlm and text_vlm.strip().replace(\" \", \"\").upper() == label:\n",
    "        correct_vlm += 1\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    try:\n",
    "        text_easy = ocr_easy_com(frame, x1, y1, x2, y2)\n",
    "    except Exception as e:\n",
    "        print(f\"[EasyOCR error on {img_name}]: {e}\")\n",
    "        text_easy = \"\"\n",
    "    time_easy += time.time() - start\n",
    "    if text_easy and text_easy.strip().replace(\" \", \"\").upper() == label:\n",
    "        correct_easy += 1\n",
    "\n",
    "total = len(image_files)\n",
    "avg_time_vlm = time_vlm / total if total > 0 else 0\n",
    "avg_time_easy = time_easy / total if total > 0 else 0\n",
    "\n",
    "print(\"\\n=== COMPARATIVA DE MODELOS ===\")\n",
    "print(f\"Número de imágenes probadas: {total}\")\n",
    "print(f\"SmolVLM (aciertos): {correct_vlm} / {total} ({correct_vlm / total:.2%})\")\n",
    "print(f\"EasyOCR (aciertos): {correct_easy} / {total} ({correct_easy / total:.2%})\")\n",
    "\n",
    "print(\"\\n=== TIEMPO MEDIO DE INFERENCIA ===\")\n",
    "print(f\"SmolVLM: {avg_time_vlm:.3f} s/img\")\n",
    "print(f\"EasyOCR: {avg_time_easy:.3f} s/img\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"DISABLE_TF_IMPORT\"] = \"1\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "\n",
    "\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from ultralytics import YOLO\n",
    "import torch, cv2, numpy as np, os, time\n",
    "from tqdm.notebook import tqdm\n",
    "import easyocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6cb6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import numpy as np\n",
    "\n",
    "reader = easyocr.Reader(['es'], gpu=False)\n",
    "\n",
    "def ocr_easy_com(frame, x1, y1, x2, y2, escala=3):\n",
    "    placa_crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "    placa_crop = cv2.resize(placa_crop, None, fx=escala, fy=escala, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    gray = cv2.cvtColor(placa_crop, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    gray = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)\n",
    "\n",
    "    results_ocr = reader.readtext(\n",
    "        gray,\n",
    "        allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
    "        detail=1\n",
    "    )\n",
    "\n",
    "    if not results_ocr:\n",
    "        return \"\"\n",
    "\n",
    "    results_sorted = sorted(results_ocr, key=lambda r: r[0][0][0])  # r[0][0][0] = x top-left\n",
    "    plate_parts = [text.strip().upper() for (_, text, _) in results_sorted]\n",
    "    license_plate = \"\".join(plate_parts)\n",
    "\n",
    "    return license_plate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prueba4_b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
